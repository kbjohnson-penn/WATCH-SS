{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3b7dbf00-8cdb-4907-809b-85647c4f52e8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Detecting Filler Speech"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "04b02eb8-d91b-47c2-bd42-4939c9241c07",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "TODO\n",
    "- Run best config for baseline plus LLM critic post-processing\n",
    "- Run LLM experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2917529a-0ba5-42a4-930d-5fd7e78fb584",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport data.adress\n",
    "%aimport data.observer\n",
    "%aimport detectors.filler_speech.keyword_search\n",
    "%aimport utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5e67d695-263e-4656-9b37-449fc567d635",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from openai import OpenAI\n",
    "from pprint import pprint\n",
    "from scipy.stats import ttest_ind, mannwhitneyu\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, roc_auc_score\n",
    "# MLFlow\n",
    "import mlflow\n",
    "from mlflow.genai.scorers import Safety, scorer\n",
    "from mlflow.entities import Feedback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "69670ea8-82e9-42cb-a7b9-93388c3a9b1e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d2add2d5-73b1-41d5-a3f4-4f774cbc1b84",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from data.adress import load_CHAT_transcripts, load_outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "53af97ae-a28c-4b02-9bb9-38bc9dd6b896",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "adress_trans = load_CHAT_transcripts()\n",
    "adress_trans = adress_trans[[\"Timestamp\", \"Speaker\", \"Transcript\", \"Transcript_clean\", \"Filler speech\"]]\n",
    "adress_trans.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b43365ec-d1ca-401d-8451-d769cc3201d2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "trn_pt_utt_idx = (adress_trans.index.get_level_values(\"split\") == \"train\") & (adress_trans[\"Speaker\"] == \"Patient\")\n",
    "tst_pt_utt_idx = (adress_trans.index.get_level_values(\"split\") == \"test\")  & (adress_trans[\"Speaker\"] == \"Patient\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d0b1d233-b0fe-40c9-b20b-e544d2911025",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Baseline: Keyword Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0e1fec84-dd98-4e1b-9e5f-7152999bd772",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from detectors.filler_speech.keyword_search import FillerKeywordDetector\n",
    "from utils import create_custom_nlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f7875448-e5c7-4133-b432-b781beb2a453",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "First, we look at the annotated fillers in the training dataset to help inform our list of keywords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cefc20e1-179a-4eac-b3c2-ce016bf36428",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "np.unique( np.concatenate(adress_trans.loc[trn_pt_utt_idx, \"Transcript\"].apply(lambda x: re.findall(r\"&(\\w+)\\s*\", x)).values) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "70e9f4f2-a448-4d53-883d-b9abb38765ec",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Then we define our keyword lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1d03e23c-6b3f-4dfe-8f2b-a28717c1e08b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b37e2393-62d1-4f36-92df-8d18be4c393d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "filler_sounds = [\n",
    "    \"ah\",\n",
    "    \"eh\",\n",
    "    \"er\",\n",
    "    \"hm\",\n",
    "    \"huh\",\n",
    "    \"mm\",\n",
    "    \"uh\",\n",
    "    \"um\",\n",
    "]\n",
    "\n",
    "filler_words = [\n",
    "    \"like\",\n",
    "    \"well\",\n",
    "    \"so\",\n",
    "    \"basically\",\n",
    "    \"actually\",\n",
    "    \"literally\",\n",
    "]\n",
    "\n",
    "filler_phrases = [\n",
    "    \"you know\",\n",
    "    \"i mean\",\n",
    "    \"i guess\",\n",
    "    \"you see\",\n",
    "]\n",
    "\n",
    "filler_letters = list(string.ascii_lowercase)\n",
    "\n",
    "filler_uncommonletters = list(filter(lambda c: c not in [\"a\", \"i\", \"o\"], filler_letters))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6de89fd4-16cf-4376-a7ae-d113ce47ddbc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Explore different keyword sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0280db3d-1842-400f-9c50-ab33dadf1a4e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8a02637a-4d76-4310-916b-184d28c8e37e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "configs = {\n",
    "    \"sounds\": (filler_sounds, False),\n",
    "    \"letters\": (filler_letters, False),\n",
    "    \"uncommonletters\": (filler_uncommonletters, False),\n",
    "    \"words\": (filler_words, False),\n",
    "    \"nonwords\": ([], True),\n",
    "    \"phrases\": (filler_phrases, False),\n",
    "    \"sounds+letters\": (filler_sounds + filler_letters, False),\n",
    "    \"sounds+uncommonletters\": (filler_sounds + filler_uncommonletters, False),\n",
    "    \"sounds+words\": (filler_sounds + filler_words, False),\n",
    "    \"sounds+nonwords\": (filler_sounds, True),\n",
    "    \"sounds+phrases\": (filler_sounds + filler_phrases, False),\n",
    "    \"sounds+uncommonletters+words\": (filler_sounds + filler_uncommonletters + filler_words, False),\n",
    "    \"sounds+uncommonletters+nonwords\": (filler_sounds + filler_uncommonletters, True),\n",
    "    \"sounds+uncommonletters+phrases\": (filler_sounds + filler_uncommonletters + filler_phrases, True),\n",
    "    \"sounds+words+nonwords\": (filler_sounds + filler_phrases, True),\n",
    "    \"sounds+nonwords+phrases\": (filler_sounds + filler_phrases, True),\n",
    "    \"sounds+uncommonletters+nonwords+words\": (filler_sounds + filler_uncommonletters + filler_words, True), # new\n",
    "    \"sounds+uncommonletters+nonwords+phrases\": (filler_sounds + filler_uncommonletters + filler_phrases, True), # new\n",
    "    \"sounds+letters+words+phrases+nonwords\": (filler_sounds+ filler_letters + filler_words + filler_phrases, True),\n",
    "    \"sounds+uncommonletters+words+nonwords+phrases\": (filler_sounds + filler_uncommonletters + filler_words + filler_phrases, True)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9fc2fa5b-bd8d-4539-8072-9be2b07956d5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def run(cfg_name, cfg, dataset):\n",
    "    # Create spaCy vocab\n",
    "    nlp = create_custom_nlp()\n",
    "    # Initialize keyword detector with config\n",
    "    d = FillerKeywordDetector(nlp, *cfg)\n",
    "    # Run detector on dataset\n",
    "    outputs = dataset[\"Transcript_clean\"].apply(d.detect)\n",
    "    # Evaluate performance\n",
    "    pred = outputs.apply(lambda x: len(x) > 0).astype(int)\n",
    "    true = dataset[\"Filler speech\"]\n",
    "    prec = precision_score(true, pred)\n",
    "    rec  = recall_score(true, pred)\n",
    "    f1   = f1_score(true, pred)\n",
    "    acc  = accuracy_score(true, pred)\n",
    "    return cfg_name, prec, rec, f1, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f0e7c802-521e-492a-bd66-86bc80b91130",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "results = Parallel(n_jobs=10, return_as=\"generator_unordered\")(delayed(run)(cfg_name, configs[cfg_name], adress_trans.loc[trn_pt_utt_idx]) for cfg_name in configs)\n",
    "results = [res for res in tqdm(results, total=len(configs))]\n",
    "\n",
    "table = pd.DataFrame(results, columns=[\"config\", \"precision\", \"recall\", \"f1\", \"accuracy\"])\n",
    "table.to_csv(\"filler_trn_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0b53131a-0d17-4e2f-abaf-1e73faafbf49",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "table.sort_values(\"recall\", ascending=False).round(3)\n",
    "# print(table.round(3).to_latex(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f76ba7fb-6a60-421b-bff0-211ffa1008be",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Evaluate best filler keyword detector configuration on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "facc283f-e95b-4e8a-8d0d-f95d6995d3b8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# create custom spaCy\n",
    "nlp = create_custom_nlp()\n",
    "# init detector\n",
    "keyword_detector_final = FillerKeywordDetector(nlp, filler_sounds + filler_uncommonletters, False)\n",
    "\n",
    "# run on all data\n",
    "outputs = adress_trans.apply(lambda x: keyword_detector_final.detect(x[\"Transcript_clean\"]) if x[\"Speaker\"] == \"Patient\" else [], axis=1)\n",
    "adress_trans[\"baseline_output\"] = outputs\n",
    "\n",
    "# report performance on test data\n",
    "true = adress_trans.loc[tst_pt_utt_idx, \"Filler speech\"]\n",
    "pred = outputs.loc[tst_pt_utt_idx].apply(lambda x: len(x) > 0).astype(int)\n",
    "print(\"TST PREC: %.3f\" % (precision_score(true, pred)))\n",
    "print(\"TST REC:  %.3f\" % (recall_score(true, pred)))\n",
    "print(\"TST F1:   %.3f\" % (f1_score(true, pred)))\n",
    "print(\"TST ACC:  %.3f\" % (accuracy_score(true, pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "99064126-774b-422c-9753-88d4f886b27f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###### Investigate the failure cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "734eebcc-180e-46d0-8b0f-28b35c2ea0b6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "temp = adress_trans.loc[trn_pt_idx].copy()\n",
    "temp[\"output\"] = outputs.loc[trn_pt_idx]\n",
    "temp[\"detected\"] = temp[\"output\"].apply(lambda x: len(x) > 0).astype(int)\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b837be51-08ff-427d-b841-9a6101235a41",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "with pd.option_context(\"display.max_rows\", None, \"display.max_colwidth\", None):\n",
    "    print(\"False positives:\")\n",
    "    print(temp.loc[(temp[\"Filler speech\"] == 0) & (temp[\"detected\"] == 1), [\"Transcript_clean\", \"output\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7f229561-cb6b-4167-8654-5b2427b3c548",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "with pd.option_context(\"display.max_rows\", None, \"display.max_colwidth\", None):\n",
    "    print(\"False negatives:\")\n",
    "    print(temp.loc[(temp[\"Filler speech\"] == 1) & (temp[\"detected\"] == 0), [\"Transcript\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "41aedfec-51a9-4580-8103-427eb14f9e48",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "doc = nlp(\"co th shor wai sau\")\n",
    "for token in doc:\n",
    "    print(token.text, token.lemma_, token.is_oov, token.is_punct, token.is_space, token._.is_silence_tag, token._.is_inaudible_tag, token._.is_event_tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "31c63454-6705-49f1-acd4-4647d1324c3d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###### (@Sriharsha) Try adding a LLM to postprocess\n",
    "We are already acheiving high performance with the keyword detector using filler sounds and uncommon letters. Can we improve performance by using an LLM to remove false positive detections?\n",
    "\n",
    "*Experiment*: For each patient session, aggregate the utterances into a transcript and the filler detection lists (remember to offset them). Query an LLM to remove detections that are not actually filler. Try 3 different LLMs once you've settled on a good prompt. Also, try using MLFlow to log LLM outputs. It makes comparing the effect of different prompt versions a little easier to visualize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4ff67260-b767-4433-a438-4486768a50e8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from utils import llm_call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "08d873df-9e04-4e52-87c8-b321b12f4bba",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "mlflow_creds = mlflow.utils.databricks_utils.get_databricks_host_creds()\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=mlflow_creds.token,\n",
    "    base_url=f\"{mlflow_creds.host}/serving-endpoints\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "747cabd4-20a2-46df-8750-3589d98b8186",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "prompt = ''''''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "12a5cfb6-95df-49bc-b3a9-6bf07cbac85b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "@scorer\n",
    "def correct(expectations, outputs):\n",
    "    return Feedback(value=(expectations[\"has_filler\"] == (len(outputs[\"fillers\"]) > 0)))\n",
    "\n",
    "scorers = [\n",
    "    Safety(),\n",
    "    correct\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9a662fcc-2798-4c7c-b5f5-6f9fbf422b08",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "temp = data.loc[\"train\"].copy()\n",
    "temp[\"filler_spans\"] = outputs[\"output\"].reset_index(level=0, drop=True)\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aa475afd-3d94-4b03-836f-f1573183295f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "(data[\"Speaker\"] + \": \" + data[\"Transcript_clean\"]).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c535626f-40a9-4647-a897-a984c802bc5b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "fn = lambda text: llm_call(client, \"openai_gpt_4o\", None, prompt.format(text), {\"type\": \"json_object\"})\n",
    "\n",
    "with mlflow.start_run(run_name=\"filler_LLMcritic_pv1\") as run:\n",
    "    result = mlflow.genai.evaluate(\n",
    "        predict_fn=fn,\n",
    "        data=trn_dataset,\n",
    "        scorers=scorers\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "37f40ed6-0e85-4ef9-9297-d2e8699b6c53",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## LLM-Based Detector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "23c4066a-04e4-4bd1-8c38-eb46d788d1f5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##### Explore different Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bee3dccd-1f1e-401a-89ae-7c722d27e1f2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# mlflow.openai.autolog()\n",
    "\n",
    "# mlflow_creds = mlflow.utils.databricks_utils.get_databricks_host_creds()\n",
    "\n",
    "# client = OpenAI(\n",
    "#     api_key=mlflow_creds.token,\n",
    "#     base_url=f\"{mlflow_creds.host}/serving-endpoints\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9931f132-0150-4659-896f-07747e6bb4e8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "prompt_v1 = '''Identify all filler sounds (e.g., \\\"uh\\\"), words (e.g., \\\"like\\\"), or phrases (e.g., \\\"you know\\\") that indicate cognitive impairment in the following utterance:\n",
    "\n",
    "{}\n",
    "\n",
    "List each instance of filler as a bullet point in the order that they are spoken. Do not include any explanations. If a filler is repeated, list each occurrence in its own bullet point. If there are no fillers, return \\\"None\\\".'''\n",
    "\n",
    "prompt_v2 = '''Your task is to identify all filler sounds (e.g., \\\"uh\\\"), words (e.g., \\\"like\\\"), or phrases (e.g., \\\"you know\\\") in text.\n",
    "\n",
    "Your output must be a single JSON object with a single key \"fillers\" whose value is JSON array of objects. Each object in the array represents one detected filler and must have the following three keys:\n",
    "- \"filler_text\": The exact filler text that was identified.\n",
    "- \"start_char\": The starting character index of the filler in the utterance.\n",
    "- \"end_char\": The index of the character *after* the last character of the filler.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d40a2959-fba4-4206-9aa4-818aa08538b9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "fn = lambda text: llm_call(client, \"openai_gpt_4o\", None, prompt.format(text), {\"type\": \"json_object\"})\n",
    "\n",
    "with mlflow.start_run(run_name=\"llm_eval_gpt4o_pv2\") as run:\n",
    "    result = mlflow.genai.evaluate(\n",
    "        predict_fn=fn,\n",
    "        data=trn_dataset,\n",
    "        scorers=scorers\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c1a9bf7a-63f3-4a32-8aa0-2b45280d1a45",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# TODO compute performance metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "20202711-4714-4627-bc5a-68e1dcf17ea8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##### Correlation with outcome variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0efabf5e-c5a9-42c9-89d9-17f6dfa40c98",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# TODO run on test data and compute feature correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f813dc56-2a6a-4fbe-83f7-246694eb797a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Summary metrics for filler detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "113c3b36-6794-4903-aa1d-dba04a9d0bc6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "outcomes = load_outcomes()\n",
    "outcomes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b57e04a7-f97a-4370-9ad0-0412eb38084c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "tst_pts = outcomes.loc[(outcomes.index.get_level_values(\"split\") == \"test\")].index.values\n",
    "tst_ad_pts = outcomes.loc[(outcomes.index.get_level_values(\"split\") == \"test\") & (outcomes[\"AD_dx\"] == 1)].index.values\n",
    "tst_cn_pts = outcomes.loc[(outcomes.index.get_level_values(\"split\") == \"test\") & (outcomes[\"AD_dx\"] == 0)].index.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1f0439a8-c347-4254-84dd-216b824316f4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Filler Rate = total number of detected fillers / total number of words spoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "84c68b79-ee25-466d-bf53-6537a10a6ac8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# filler rate\n",
    "num = outputs.apply(len).groupby(level=(\"split\", \"ID\")).sum()\n",
    "den = adress_trans.apply(lambda x: sum([1 for token in nlp(x[\"Transcript_clean\"]) if not (token.is_punct or token.is_space or token._.is_silence_tag or token._.is_inaudible_tag or token._.is_event_tag)]) if x[\"Speaker\"] == \"Patient\" else 0, axis=1).groupby(level=(\"split\", \"ID\")).sum()\n",
    "filler_rates = 100 * num / den"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4a2c88c8-cc09-476e-9e8b-35ce3e4bcced",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "plt.violinplot(\n",
    "    (filler_rates.loc[tst_ad_pts],\n",
    "     filler_rates.loc[tst_cn_pts]),\n",
    "    showmedians=True,\n",
    ")\n",
    "plt.xticks([1, 2], [\"AD Group\", \"Control Group\"])\n",
    "plt.ylim([0, 100])\n",
    "plt.ylabel(\"Filler Rate\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "47421b88-305a-4c87-bddb-4d642464a42f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Mean and stddev number of words between fillers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e2acf9e4-9bbd-4fa8-bc27-06ccfbb700a4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# mean/std number of words between fillers\n",
    "num_words_btwn_fillers = pd.DataFrame(index=filler_rates.index, columns=[\"mean\", \"std\", \"mean_norm\", \"std_norm\"], dtype=float)\n",
    "for i, grp in adress_trans.groupby(level=(\"split\", \"ID\")):\n",
    "    pt_utts = grp.loc[grp[\"Speaker\"] == \"Patient\", \"Transcript_clean\"]\n",
    "    pt_trans = \" \".join(pt_utts)\n",
    "    pt_fillers = grp.loc[grp[\"Speaker\"] == \"Patient\", \"baseline_output\"]\n",
    "    # print(pt_utts)\n",
    "    # print(pt_trans)\n",
    "    # print(pt_fillers)\n",
    "\n",
    "    ## get word-level character spans\n",
    "    doc = nlp(pt_trans)\n",
    "    # remove spaces, punctuation, and tags\n",
    "    word_spans = [(token.idx, token.idx + len(token.text), token.text) for token in doc if not (token.is_punct or token.is_space or token._.is_silence_tag or token._.is_inaudible_tag or token._.is_event_tag)]\n",
    "    # print(word_spans)\n",
    "    # break\n",
    "\n",
    "    ## offset character spans\n",
    "    offset = 0\n",
    "    for j in range(pt_fillers.shape[0] - 1):\n",
    "        offset += len(pt_utts.loc[i].iloc[j]) + 1\n",
    "        pt_fillers.loc[i].iloc[j+1] = [(span[0] + offset, span[1] + offset, span[2]) for span in pt_fillers.loc[i].iloc[j+1]]\n",
    "\n",
    "    filler_spans = pt_fillers.sum()\n",
    "    # print(filler_spans)\n",
    "    # break\n",
    "\n",
    "    ## compute metrics\n",
    "    filler_word_idxs = [word_spans.index(span) for span in pt_fillers.sum()]\n",
    "    dist_btwn_fillers = [filler_word_idxs[i] - filler_word_idxs[i-1] for i in range(1, len(filler_word_idxs))]\n",
    "    num_words_btwn_fillers.loc[i, \"mean\"] = np.mean(dist_btwn_fillers) if len(dist_btwn_fillers) > 0 else len(word_spans)\n",
    "    num_words_btwn_fillers.loc[i, \"std\"] = np.std(dist_btwn_fillers) if len(dist_btwn_fillers) > 0 else 0.0\n",
    "    num_words_btwn_fillers.loc[i, \"mean_norm\"] = num_words_btwn_fillers.loc[i, \"mean\"] / len(word_spans)\n",
    "    num_words_btwn_fillers.loc[i, \"std_norm\"] = num_words_btwn_fillers.loc[i, \"std\"] / len(word_spans)\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "59a356c8-dcc6-4362-abf7-8b49b593d505",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "plt.violinplot(\n",
    "    (num_words_btwn_fillers.loc[tst_ad_pts, \"mean\"],\n",
    "     num_words_btwn_fillers.loc[tst_cn_pts, \"mean\"],\n",
    "     num_words_btwn_fillers.loc[tst_ad_pts, \"std\"],\n",
    "     num_words_btwn_fillers.loc[tst_cn_pts, \"std\"]),\n",
    "    showmedians=True,\n",
    ")\n",
    "plt.xticks(range(1, 5), [\"Mean AD Group\", \"Mean Control Group\", \"Std AD Group\", \"Std Control Group\"], rotation=45, ha=\"right\")\n",
    "plt.ylabel(\"Filler Rate\")\n",
    "plt.grid()\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d7cf9e25-899c-4ce0-ad40-e7c8f3c3eb89",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "plt.violinplot(\n",
    "    (num_words_btwn_fillers.loc[tst_ad_pts, \"mean_norm\"],\n",
    "     num_words_btwn_fillers.loc[tst_cn_pts, \"mean_norm\"],\n",
    "     num_words_btwn_fillers.loc[tst_ad_pts, \"std_norm\"],\n",
    "     num_words_btwn_fillers.loc[tst_cn_pts, \"std_norm\"]),\n",
    "    showmedians=True,\n",
    ")\n",
    "plt.xticks(range(1, 5), [\"Mean (norm) AD Group\", \"Mean (norm) Control Group\", \"Std (norm) AD Group\", \"Std (norm) Control Group\"], rotation=45, ha=\"right\")\n",
    "plt.ylabel(\"Filler Rate\")\n",
    "plt.grid()\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cf326db3-df09-4c85-851f-7ec47aa5d098",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Analyze correlation between our metrics and the outcome variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9792a23b-eca3-47b1-bf21-3eb32c7fe131",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "for metric, scores in zip([\"filler rate\", \"mean words between fillers\", \"std words between fillers\"], [filler_rates, num_words_btwn_fillers[\"mean\"], num_words_btwn_fillers[\"std\"]]):\n",
    "    # score averages\n",
    "    mean_ad = scores.loc[tst_ad_pts].mean()\n",
    "    std_ad = scores.loc[tst_ad_pts].std()\n",
    "    mean_cn = scores.loc[tst_cn_pts].mean()\n",
    "    std_cn = scores.loc[tst_cn_pts].std()\n",
    "\n",
    "    # correlation metrics\n",
    "    res_ttest = ttest_ind(outcomes.loc[tst_pts, \"AD_dx\"], scores.loc[tst_pts])\n",
    "    res_mannw = mannwhitneyu(outcomes.loc[tst_pts, \"AD_dx\"], scores.loc[tst_pts])\n",
    "    res_auc   = roc_auc_score(outcomes.loc[tst_pts, \"AD_dx\"], scores.loc[tst_pts])\n",
    "\n",
    "    print(\"%s & %.2f (%.2f) & %.2f (%.2f) & %.2f (%s) & %.2f (%s) & %.2f \\\\\\\\\" % (metric,\n",
    "                                                                    mean_ad,\n",
    "                                                                    std_ad,\n",
    "                                                                    mean_cn,\n",
    "                                                                    std_cn,\n",
    "                                                                    res_ttest.statistic,\n",
    "                                                                    str(round(res_ttest.pvalue, 3)) if res_ttest.pvalue >= 0.001 else \"<0.001\", \n",
    "                                                                    res_mannw.statistic, \n",
    "                                                                    str(round(res_ttest.pvalue, 3)) if res_ttest.pvalue >= 0.001 else \"<0.001\",\n",
    "                                                                    res_auc)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "96343732-58d6-41c3-b172-00f6b3a61a0c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## External Validation on Penn Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "73db0f80-a5bd-4b12-88fd-fb56920a2ccc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from data.observer import load_penn_transcripts, load_penn_outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0ee7bf7d-3bc5-4581-a32f-4850670bbae1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "penn_trans = load_penn_transcripts()\n",
    "penn_trans.head()\n",
    "# TODO add zero padding to ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "da0a8ab6-4bd7-4b9e-8e12-ad8062a818db",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "trans.index.get_level_values(\"provider_id\").map(lambda x: f\"PR{int(str(x)[2:]):03d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "760d56de-124b-44f1-b15f-d504e37d4002",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "penn_outcomes = load_penn_outcomes()\n",
    "penn_outcomes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0a37d020-2f70-4ba1-8442-8e9d584b567d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# run on data\n",
    "outputs = penn_trans.apply(lambda x: keyword_detector_final.detect(x[\"Transcript\"]) if x[\"Speaker\"] == \"Patient\" else [], axis=1)\n",
    "# compute filler rates\n",
    "num = outputs.apply(len).groupby(level=\"visit_file\").sum()\n",
    "den = penn_trans.apply(lambda x: len(re.findall(r'\\w+', x[\"Transcript\"])) if x[\"Speaker\"] == \"Patient\" else 0, axis=1).groupby(level=\"visit_file\").sum()\n",
    "filler_rates = 100 * num / den"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "38ae9738-0c73-450e-88e6-19b96858ad1f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "ttest_ind(penn_outcomes.loc[filler_rates.index, \"AD_dx\"], filler_rates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fe17e80e-a814-45a1-aeef-b68321bef4a4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "mannwhitneyu(penn_outcomes.loc[filler_rates.index, \"AD_dx\"], filler_rates)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "03_Filler_Speech",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
