{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3b7dbf00-8cdb-4907-809b-85647c4f52e8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Detecting Filler Speech\n",
    "\n",
    "**TODO**:\n",
    "- Generator + LLM Critic experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2917529a-0ba5-42a4-930d-5fd7e78fb584",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport data.adress\n",
    "%aimport detectors.filler_speech.keyword_search\n",
    "%aimport utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5e67d695-263e-4656-9b37-449fc567d635",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from pprint import pprint\n",
    "# Evaluation\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import ttest_ind, mannwhitneyu\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, roc_auc_score\n",
    "# Generative AI\n",
    "from openai import OpenAI\n",
    "from utils import llm_call\n",
    "import mlflow\n",
    "from mlflow.genai.scorers import Safety, scorer\n",
    "from mlflow.entities import Feedback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "69670ea8-82e9-42cb-a7b9-93388c3a9b1e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d2add2d5-73b1-41d5-a3f4-4f774cbc1b84",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from data.adress import load_transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "53af97ae-a28c-4b02-9bb9-38bc9dd6b896",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "adress_trans = load_transcripts()\n",
    "adress_trans = adress_trans[[\"Timestamp\", \"Speaker\", \"Transcript\", \"Transcript_clean\", \"Filler\"]]\n",
    "\n",
    "# Extract annotation based count of fillers\n",
    "adress_trans[\"num_fillers\"] = adress_trans[\"Transcript\"].apply(lambda x: len(re.findall(r\"&(?!=)\", x)))\n",
    "\n",
    "adress_trans.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2fb1c834-5fec-4739-92a9-79018d2bf209",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "trn_pt_utt_idx = (adress_trans.index.get_level_values(\"split\") == \"train\") & (adress_trans[\"Speaker\"] == \"Patient\")\n",
    "dev_pt_utt_idx = (adress_trans.index.get_level_values(\"split\") == \"dev\")   & (adress_trans[\"Speaker\"] == \"Patient\")\n",
    "tst_pt_utt_idx = (adress_trans.index.get_level_values(\"split\") == \"test\")  & (adress_trans[\"Speaker\"] == \"Patient\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d0b1d233-b0fe-40c9-b20b-e544d2911025",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Baseline: Keyword Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0e1fec84-dd98-4e1b-9e5f-7152999bd772",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from detectors.filler_speech.keyword_search import FillerKeywordDetector\n",
    "from utils import create_custom_nlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f7875448-e5c7-4133-b432-b781beb2a453",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "First, we look at the annotated fillers in the development dataset to help inform our list of keywords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cefc20e1-179a-4eac-b3c2-ce016bf36428",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "np.unique( np.concatenate(adress_trans.loc[dev_pt_utt_idx, \"Transcript\"].apply(lambda x: re.findall(r\"&(\\w+)\\s*\", x)).values) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "70e9f4f2-a448-4d53-883d-b9abb38765ec",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Then we define our keyword lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1d03e23c-6b3f-4dfe-8f2b-a28717c1e08b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b37e2393-62d1-4f36-92df-8d18be4c393d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "filler_sounds = [\n",
    "    \"ah\",\n",
    "    \"eh\",\n",
    "    \"er\",\n",
    "    \"hm\",\n",
    "    \"huh\",\n",
    "    \"mm\",\n",
    "    \"uh\",\n",
    "    \"um\",\n",
    "]\n",
    "\n",
    "filler_words = [\n",
    "    \"like\",\n",
    "    \"well\",\n",
    "    \"so\",\n",
    "    \"basically\",\n",
    "    \"actually\",\n",
    "    \"literally\",\n",
    "]\n",
    "\n",
    "filler_phrases = [\n",
    "    \"you know\",\n",
    "    \"i mean\",\n",
    "    \"i guess\",\n",
    "    \"you see\",\n",
    "]\n",
    "\n",
    "filler_letters = list(string.ascii_lowercase)\n",
    "\n",
    "filler_uncommonletters = list(filter(lambda c: c not in [\"a\", \"i\", \"o\"], filler_letters))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6de89fd4-16cf-4376-a7ae-d113ce47ddbc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Explore different keyword sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0280db3d-1842-400f-9c50-ab33dadf1a4e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8a02637a-4d76-4310-916b-184d28c8e37e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "configs = {\n",
    "    \"sounds\": (filler_sounds, False),\n",
    "    \"letters\": (filler_letters, False),\n",
    "    \"uncommonletters\": (filler_uncommonletters, False),\n",
    "    \"words\": (filler_words, False),\n",
    "    \"nonwords\": ([], True),\n",
    "    \"phrases\": (filler_phrases, False),\n",
    "    \"sounds+letters\": (filler_sounds + filler_letters, False),\n",
    "    \"sounds+uncommonletters\": (filler_sounds + filler_uncommonletters, False),\n",
    "    \"sounds+words\": (filler_sounds + filler_words, False),\n",
    "    \"sounds+nonwords\": (filler_sounds, True),\n",
    "    \"sounds+phrases\": (filler_sounds + filler_phrases, False),\n",
    "    \"sounds+uncommonletters+words\": (filler_sounds + filler_uncommonletters + filler_words, False),\n",
    "    \"sounds+uncommonletters+nonwords\": (filler_sounds + filler_uncommonletters, True),\n",
    "    \"sounds+uncommonletters+phrases\": (filler_sounds + filler_uncommonletters + filler_phrases, True),\n",
    "    \"sounds+words+nonwords\": (filler_sounds + filler_phrases, True),\n",
    "    \"sounds+nonwords+phrases\": (filler_sounds + filler_phrases, True),\n",
    "    \"sounds+uncommonletters+nonwords+words\": (filler_sounds + filler_uncommonletters + filler_words, True), # new\n",
    "    \"sounds+uncommonletters+nonwords+phrases\": (filler_sounds + filler_uncommonletters + filler_phrases, True), # new\n",
    "    \"sounds+letters+words+phrases+nonwords\": (filler_sounds+ filler_letters + filler_words + filler_phrases, True),\n",
    "    \"sounds+uncommonletters+words+nonwords+phrases\": (filler_sounds + filler_uncommonletters + filler_words + filler_phrases, True)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9fc2fa5b-bd8d-4539-8072-9be2b07956d5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def run(cfg_name, cfg, dataset):\n",
    "    # Create spaCy vocab\n",
    "    nlp = create_custom_nlp()\n",
    "    # Initialize keyword detector with config\n",
    "    d = FillerKeywordDetector(nlp, *cfg)\n",
    "    # Run detector on dataset\n",
    "    outputs = dataset[\"Transcript_clean\"].apply(d.detect)\n",
    "    # Evaluate performance\n",
    "    true = dataset[\"Filler\"]\n",
    "    pred = outputs.apply(lambda x: len(x[\"detections\"]) > 0).astype(int)\n",
    "    prec = precision_score(true, pred)\n",
    "    rec  = recall_score(true, pred)\n",
    "    f1   = f1_score(true, pred)\n",
    "    acc  = accuracy_score(true, pred)\n",
    "    return cfg_name, prec, rec, f1, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f0e7c802-521e-492a-bd66-86bc80b91130",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "results = Parallel(n_jobs=10, return_as=\"generator_unordered\")(delayed(run)(cfg_name, configs[cfg_name], adress_trans.loc[trn_pt_utt_idx]) for cfg_name in configs)\n",
    "results = [res for res in tqdm(results, total=len(configs))]\n",
    "\n",
    "table = pd.DataFrame(results, columns=[\"config\", \"precision\", \"recall\", \"f1\", \"accuracy\"])\n",
    "table.to_csv(\"filler_trn_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0b53131a-0d17-4e2f-abaf-1e73faafbf49",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "table.sort_values(\"recall\", ascending=False).round(3)\n",
    "# print(table.round(3).to_latex(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f76ba7fb-6a60-421b-bff0-211ffa1008be",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Evaluate best filler keyword detector configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "facc283f-e95b-4e8a-8d0d-f95d6995d3b8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# create custom spaCy\n",
    "nlp = create_custom_nlp()\n",
    "# init detector\n",
    "keyword_detector_final = FillerKeywordDetector(nlp, filler_sounds + filler_uncommonletters, False)\n",
    "\n",
    "# run on all data\n",
    "adress_trans[\"keyword_dets\"] = adress_trans.apply(lambda x: keyword_detector_final.detect(x[\"Transcript_clean\"]) if x[\"Speaker\"] == \"Patient\" else pd.NA, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c668f231-f8e6-4521-bf9f-19cfd82eb711",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###### Performance on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fd9c1a7a-fad7-4677-823c-9d3fb2a4dbb6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def evaluate(true, pred):\n",
    "    prec = precision_score(true, pred)\n",
    "    rec  = recall_score(true, pred)\n",
    "    f1   = f1_score(true, pred)\n",
    "    acc  = accuracy_score(true, pred)\n",
    "    return f\"{prec:.3f} & {rec:.3f} & {f1:.3f} & {acc:.3f} \\\\\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "82702ebf-557c-4640-9cc9-cc0d476065f7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "true = adress_trans.loc[tst_pt_utt_idx, \"Filler\"]\n",
    "pred = adress_trans.loc[tst_pt_utt_idx, \"keyword_dets\"].apply(lambda x: len(x[\"detections\"]) > 0).astype(int)\n",
    "print(evaluate(true, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "37f40ed6-0e85-4ef9-9297-d2e8699b6c53",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## LLM-Based Detector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "23c4066a-04e4-4bd1-8c38-eb46d788d1f5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##### Explore different Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bee3dccd-1f1e-401a-89ae-7c722d27e1f2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "mlflow_creds = mlflow.utils.databricks_utils.get_databricks_host_creds()\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=mlflow_creds.token,\n",
    "    base_url=f\"{mlflow_creds.host}/serving-endpoints\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9931f132-0150-4659-896f-07747e6bb4e8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# v1\n",
    "'''# INSTRUCTIONS\n",
    "You are a neurologist analyzing a patient's speech sample for signs of cognitive impairment. Your task is to identify the use of filler words in the provided utterance below. Filler words are sounds, words, or phrases used to fill pauses in speech during speech planning (e.g., \"uh\", \"like\", \"you know\").\n",
    "\n",
    "# OUTPUT FORMAT\n",
    "Your output must be a single JSON object with a single key \"detections\" whose value is an array of JSON objects. Each object in the array represents one detected filler and must have the following three keys-value pairs:\n",
    "- \"type\": \"filler\".\n",
    "- \"text\": The exact filler text that was identified.\n",
    "- \"span\": The character span of the filler in the utterance.\n",
    "\n",
    "# INPUT\n",
    "{}\n",
    "'''\n",
    "\n",
    "# v2\n",
    "'''# INSTRUCTIONS\n",
    "You are a neurologist analyzing a patient's speech sample for signs of cognitive impairment. Your task is to identify the use of filler words in the provided utterance below. Filler words are sounds, words, or phrases used to fill pauses in speech during speech planning (e.g., \"uh\", \"like\", \"you know\").\n",
    "\n",
    "Your output must be a single JSON object with a single key \"detections\" whose value is an array of JSON objects. Each object in the array represents one detected filler and must have the following three keys-value pairs:\n",
    "- \"type\": \"filler\".\n",
    "- \"text\": The exact filler text that was identified.\n",
    "- \"span\": The character span of the filler in the utterance.\n",
    "\n",
    "# UTTERANCE\n",
    "{}\n",
    "'''\n",
    "\n",
    "#v3\n",
    "prompt = '''# INSTRUCTIONS\n",
    "You are a neurologist analyzing a patient's speech sample for signs of cognitive impairment. Your task is to identify the use of filler words in the provided utterance below. Filler words are sounds, words, or phrases used to fill pauses in speech during speech planning (e.g., \"uh\", \"like\", \"you know\"). Do not flag word repetiton as filler. Do not flag event tags of the format \"[<event>]\" as filler.\n",
    "\n",
    "Your output must be a single JSON object with a single key \"detections\" whose value is an array of JSON objects. Each object in the array represents one detected filler and must have the following three keys-value pairs:\n",
    "- \"type\": \"filler\".\n",
    "- \"text\": The exact filler text that was identified.\n",
    "- \"span\": The character span of the filler in the utterance.\n",
    "\n",
    "# UTTERANCE\n",
    "{}\n",
    "'''\n",
    "\n",
    "#v4\n",
    "'''# INSTRUCTIONS\n",
    "You are a neurologist analyzing a patient's speech sample for signs of cognitive impairment. Your task is to identify the use of filler words in the provided utterance below. Filler words are sounds, words, or phrases used to fill pauses in speech during speech planning (e.g., \"uh\", \"like\", \"you know\"). Do not flag word repetiton as filler. Do not flag event tags of the format \"[<event>]\" as filler. Do not flag event tags of the format \"[<event>]\" as filler. Do not flag word repetiton as filler. Every detected filler MUST be an exact, verbatim substring of the input utterance.\n",
    "\n",
    "Your output must be a single JSON object with a single key \"detections\" whose value is an array of JSON objects. Each object in the array represents one detected filler and must have the following three keys-value pairs:\n",
    "- \"type\": \"filler\".\n",
    "- \"text\": The exact text of the detected filler from the utterance.\n",
    "- \"span\": The character span of the filler in the utterance.\n",
    "\n",
    "# UTTERANCE\n",
    "{}\n",
    "'''\n",
    "\n",
    "#v5\n",
    "'''# INSTRUCTIONS\n",
    "You are a neurologist analyzing a patient's speech sample for signs of cognitive impairment. Your task is to identify the use of filler words in the provided utterance below. Filler words are sounds, words, or phrases used to fill pauses in speech during speech planning (e.g., \"uh\", \"like\", \"you know\"). Do not flag word repetiton as filler. Do not flag event tags of the format \"[<event>]\" as filler.\n",
    "\n",
    "Your output must be a single JSON object with a single key \"detections\" whose value is an array of JSON objects. Each object in the array represents one detected filler and must have the following three keys-value pairs:\n",
    "- \"type\": \"filler\".\n",
    "- \"text\": The verbatim substring from the utterance that was identified as the filler.\n",
    "- \"span\": The character span of the filler in the utterance.\n",
    "\n",
    "# UTTERANCE\n",
    "{}\n",
    "'''\n",
    "\n",
    "#v6\n",
    "'''# INSTRUCTIONS\n",
    "You are a neurologist analyzing a patient's speech sample for signs of cognitive impairment. Your task is to identify the use of filler words in the provided utterance below. Filler words -- such as \"uh\", \"like\", \"you know\" -- are sounds, words, or phrases used to fill pauses in speech while formulating what to say next. Do not flag word repetiton as filler. Do not flag event tags of the format \"[<event>]\" as filler.\n",
    "\n",
    "Your output must be a single JSON object with a single key \"detections\" whose value is an array of JSON objects. Each object in the array represents one detected filler and must have the following three keys-value pairs:\n",
    "- \"type\": \"filler\".\n",
    "- \"text\": The verbatim substring from the utterance that was identified as the filler.\n",
    "- \"span\": The character span of the filler in the utterance.\n",
    "\n",
    "# UTTERANCE\n",
    "{}\n",
    "'''\n",
    "\n",
    "#v7\n",
    "prompt = '''# INSTRUCTIONS\n",
    "You are a neurologist analyzing a patient's speech sample for signs of cognitive impairment. Your task is to identify the use of filler words in the provided utterance below. Filler words are sounds (like \"uh\", \"um\"), fragments (like \"r\", \"sh\"), words (like \"well\", \"like\"), or phrases (like \"I mean\", \"you know\") used to fill pauses in speech while formulating what to say next. Do not flag word repetiton as filler. Do not flag event tags of the format \"[<event>]\" as filler.\n",
    "\n",
    "Your output must be a single JSON object with a single key \"detections\" whose value is an array of JSON objects. Each object in the array represents one detected filler and must have the following three keys-value pairs:\n",
    "- \"type\": \"filler\".\n",
    "- \"text\": The verbatim substring from the utterance that was identified as the filler.\n",
    "- \"span\": The character span of the filler in the utterance.\n",
    "\n",
    "# UTTERANCE\n",
    "{}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f5dd8c69-58fe-4665-8209-d9b53e17eb19",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "trn_dataset = []\n",
    "for idx, row in adress_trans.loc[trn_pt_utt_idx].iterrows():\n",
    "    trn_dataset.append({\n",
    "        \"split\": idx[0],\n",
    "        \"ID\": idx[1],\n",
    "        \"utt_num\": idx[2],\n",
    "        \"inputs\": {\"text\": row[\"Transcript_clean\"]},\n",
    "        \"expectations\": {\"has_filler\": bool(row[\"Filler\"])}\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "12a5cfb6-95df-49bc-b3a9-6bf07cbac85b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "@scorer\n",
    "def correct(expectations, outputs):\n",
    "    return Feedback(value=(expectations[\"has_filler\"] == (len(outputs[\"detections\"]) > 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d40a2959-fba4-4206-9aa4-818aa08538b9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "fn = lambda text: llm_call(client, \"openai_gpt_4o\", None, prompt.format(text), {\"type\": \"json_object\"})\n",
    "\n",
    "with mlflow.start_run(run_name=\"llm_trn_gpt4o_pV7_2\") as run:\n",
    "    gpt_dets_trn = mlflow.genai.evaluate(\n",
    "        predict_fn=fn,\n",
    "        data=trn_dataset,\n",
    "        scorers=[correct]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f1a12d52-399f-4b74-a2b4-23fbf7827bc6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def process_mlflow_outputs(result):\n",
    "    outputs = result.tables[\"eval_results\"][[\"response\", \"assessments\"]]\n",
    "    outputs[\"pred\"] = outputs[\"response\"].apply(lambda x: (len(x[\"detections\"]) > 0) if type(x) == dict else False).astype(int)\n",
    "    outputs[\"label\"] = outputs[\"assessments\"].apply(lambda x: [a[\"value\"] for a in x if a[\"name\"] == \"has_filler\"][0]).astype(int)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "be0a2be4-0b70-4518-ac17-7a38c75d847b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "outputs = process_mlflow_outputs(gpt_dets_trn)\n",
    "print(evaluate(outputs[\"label\"], outputs[\"pred\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "947639f9-b672-4662-be77-1635c7bf8f60",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##### Compare performance of different LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3f2cfa29-22a6-4cfe-9cd7-f12e81729158",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "fn = lambda text: llm_call(client, \"meta_llama_v3_1_8b_instruct\", None, prompt.format(text), {\"type\": \"json_object\"})\n",
    "\n",
    "with mlflow.start_run(run_name=\"llm_eval_llama3_1_8b_pV7_2\") as run:\n",
    "    llama_dets_trn = mlflow.genai.evaluate(\n",
    "        predict_fn=fn,\n",
    "        data=trn_dataset,\n",
    "        scorers=[correct]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6702b4da-32b6-4f50-986b-fa2a67015e0c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "outputs = process_mlflow_outputs(llama_dets_trn)\n",
    "print(evaluate(outputs[\"label\"], outputs[\"pred\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8ba890ec-55b8-4a0c-a01e-9f375a529c13",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Llama actually performs extremely terrible with this prompt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4a5de8bd-9d21-405c-b742-28bb5d3e58b1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##### Evaluate the best configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a62b6d16-e032-4fb0-8fa8-f784ee440705",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "tst_dataset = []\n",
    "for idx, row in adress_trans.loc[tst_pt_utt_idx].iterrows():\n",
    "    tst_dataset.append({\n",
    "        \"split\": idx[0],\n",
    "        \"ID\": idx[1],\n",
    "        \"utt_num\": idx[2],\n",
    "        \"inputs\": {\"text\": row[\"Transcript_clean\"]},\n",
    "        \"expectations\": {\"has_filler\": bool(row[\"Filler\"])}\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e8476bfb-cb2d-40dc-9071-c2e14396eb7e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "fn = lambda text: llm_call(client, \"openai_gpt_4o\", None, prompt.format(text), {\"type\": \"json_object\"})\n",
    "\n",
    "with mlflow.start_run(run_name=\"gpt_eval_tst\") as run:\n",
    "    gpt_dets_tst = mlflow.genai.evaluate(\n",
    "        predict_fn=fn,\n",
    "        data=tst_dataset,\n",
    "        scorers=[correct]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c1a9bf7a-63f3-4a32-8aa0-2b45280d1a45",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "outputs = process_mlflow_outputs(gpt_dets_tst)\n",
    "print(evaluate(outputs[\"label\"], outputs[\"pred\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "31c63454-6705-49f1-acd4-4647d1324c3d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## (@Sriharsha) Try using a LLM critic to post-process keyword detections.\n",
    "We are already acheiving high performance with the keyword detector using filler sounds and uncommon letters. Can we improve performance by using an LLM to remove false positive detections?\n",
    "\n",
    "*Experiment*: For each patient session, aggregate the utterances into a transcript and the filler detection lists (remember to offset them). Query an LLM to remove detections that are not actually filler. Try 3 different LLMs once you've settled on a good prompt. Also, try using MLFlow to log LLM outputs. It makes comparing the effect of different prompt versions a little easier to visualize."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "99064126-774b-422c-9753-88d4f886b27f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##### Investigate the failure cases or prior methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c2ad4711-6a0e-4da7-acba-1428802aa6d2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Keyword search detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b837be51-08ff-427d-b841-9a6101235a41",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "with pd.option_context(\"display.max_rows\", None, \"display.max_colwidth\", None):\n",
    "    print(\"False positives:\")\n",
    "    pprint(adress_trans.loc[dev_pt_utt_idx & (adress_trans[\"Filler\"] == 0) & (adress_trans[\"keyword_dets\"].apply(lambda x: len(x[\"detections\"]) > 0 if type(x) == dict else False)), [\"Transcript\", \"keyword_dets\"]].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7f229561-cb6b-4167-8654-5b2427b3c548",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "with pd.option_context(\"display.max_rows\", None, \"display.max_colwidth\", None):\n",
    "    print(\"False negatives:\")\n",
    "    pprint(adress_trans.loc[dev_pt_utt_idx & (adress_trans[\"Filler\"] == 1) & (adress_trans[\"keyword_dets\"].apply(lambda x: len(x[\"detections\"]) == 0 if type(x) == dict else False)), [\"Transcript\", \"keyword_dets\"]].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8492cc8c-71f1-4de2-8c2c-ae59d121d992",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "LLM-based detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "90dc96e2-4a99-43be-a26c-3f4549af9529",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "with pd.option_context(\"display.max_rows\", None, \"display.max_colwidth\", None):\n",
    "    print(\"False positives:\")\n",
    "    pprint(adress_trans.loc[dev_pt_utt_idx & (adress_trans[\"Filler\"] == 0) & (adress_trans[\"llm_dets\"].apply(lambda x: len(x[\"detections\"]) > 0 if type(x) == dict else False)), [\"Transcript\", \"llm_dets\"]].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d6022318-816a-48e1-9c84-f2280986076f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "with pd.option_context(\"display.max_rows\", None, \"display.max_colwidth\", None):\n",
    "    print(\"False negatives:\")\n",
    "    pprint(adress_trans.loc[dev_pt_utt_idx & (adress_trans[\"Filler\"] == 1) & (adress_trans[\"llm_dets\"].apply(lambda x: len(x[\"detections\"]) == 0 if type(x) == dict else False)), [\"Transcript\", \"llm_dets\"]].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b522a21f-f056-41df-b9e0-aa4597d65078",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##### Explore different prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "747cabd4-20a2-46df-8750-3589d98b8186",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# @Sriharsha Have the llm output a json object with the key \"fillers\" whose value is a list of json objects for each detection. Each detection object must have a \"text\" key whose value is the filler sound/word/phrase and a \"span\" key whose value is a list of the start and end character index of the filler in the utterance.\n",
    "\n",
    "critic_prompt = '''{}'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5b1e65e8-a348-44b5-a38e-f2d183dbc2ea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dataset_kw = []\n",
    "dataset_llm = []\n",
    "dataset = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c535626f-40a9-4647-a897-a984c802bc5b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "fn = lambda transcript, detections: llm_call(client, \"openai_gpt_4o\", None, critic_prompt.format(transcript, detections), {\"type\": \"json_object\"})\n",
    "\n",
    "with mlflow.start_run(run_name=\"Keywords + Critic pv0\") as run:\n",
    "    result = mlflow.genai.evaluate(\n",
    "        predict_fn=fn,\n",
    "        data=dataset,\n",
    "        scorers=[correct]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "573a4dca-c591-4cde-9238-4d6092b13617",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##### Evaluate the best prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8c1bc22d-3baa-434f-8395-9c8b2c0dcf05",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "fn = lambda text: llm_call(client, \"openai_gpt_4o\", None, critic_prompt.format(text), {\"type\": \"json_object\"})\n",
    "\n",
    "with mlflow.start_run(run_name=\"LLM + Critic pv0\") as run:\n",
    "    result = mlflow.genai.evaluate(\n",
    "        predict_fn=fn,\n",
    "        data=dataset_kw,\n",
    "        scorers=[correct]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bbe211f9-5cbd-4326-be0d-9a5fc0dc3c0b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "fn = lambda text: llm_call(client, \"openai_gpt_4o\", None, critic_prompt.format(text), {\"type\": \"json_object\"})\n",
    "\n",
    "with mlflow.start_run(run_name=\"LLM + Critic pv0\") as run:\n",
    "    result = mlflow.genai.evaluate(\n",
    "        predict_fn=fn,\n",
    "        data=dataset_llm,\n",
    "        scorers=[correct]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f813dc56-2a6a-4fbe-83f7-246694eb797a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Summary metrics for filler detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2e96e512-fc2a-41c7-bb6e-0a141ed0c273",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from data.adress import load_outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "113c3b36-6794-4903-aa1d-dba04a9d0bc6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "outcomes = load_outcomes()\n",
    "outcomes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b57e04a7-f97a-4370-9ad0-0412eb38084c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "tst_pts = outcomes.loc[(outcomes.index.get_level_values(\"split\") == \"test\")].index.values\n",
    "tst_ad_pts = outcomes.loc[(outcomes.index.get_level_values(\"split\") == \"test\") & (outcomes[\"AD_dx\"] == 1)].index.values\n",
    "tst_cn_pts = outcomes.loc[(outcomes.index.get_level_values(\"split\") == \"test\") & (outcomes[\"AD_dx\"] == 0)].index.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1f0439a8-c347-4254-84dd-216b824316f4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Filler Rate** = Total number of detected fillers / Total number of words spoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "df58f0f8-d8fb-46a4-994f-b03bdd3c8c44",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def compute_filler_rate(outputs):\n",
    "    num = outputs.apply(lambda x: len(x[\"detections\"]) if not pd.isna(x) else 0).groupby(level=(\"split\", \"ID\")).sum()\n",
    "    den = adress_trans.apply(lambda x: sum([1 for token in nlp(x[\"Transcript_clean\"]) if not (token.is_punct or token.is_space or token._.is_silence_tag or token._.is_inaudible_tag or token._.is_event_tag)]) if x[\"Speaker\"] == \"Patient\" else 0, axis=1).groupby(level=(\"split\", \"ID\")).sum()\n",
    "    return 100 * num / den"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6aafe707-5b1f-4f44-8cf5-9bc85098c7c1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "outcomes[\"gt_filler_rate\"] = compute_filler_rate(adress_trans[\"num_fillers\"].apply(lambda x: {\"detections\": [0] * x}))\n",
    "outcomes[\"kw_filler_rate\"] = compute_filler_rate(adress_trans[\"keyword_dets\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4a2c88c8-cc09-476e-9e8b-35ce3e4bcced",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "plt.violinplot(\n",
    "    (outcomes.loc[tst_ad_pts, \"gt_filler_rates\"],\n",
    "     outcomes.loc[tst_cn_pts, \"gt_filler_rates\"],\n",
    "     outcomes.loc[tst_ad_pts, \"kw_filler_rates\"],\n",
    "     outcomes.loc[tst_cn_pts, \"kw_filler_rates\"]),\n",
    "    showmedians=True,\n",
    ")\n",
    "plt.xticks(range(1, 5), [\"GT AD Group\", \"GT Control Group\", \"KW AD Group\", \"KW Control Group\"])\n",
    "plt.ylim([0, 100])\n",
    "plt.ylabel(\"Filler Rate\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "47421b88-305a-4c87-bddb-4d642464a42f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Inter filler Distance**: The mean and standard deviation of the number of words between fillers within utterances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ad0fe4d0-2ff1-4574-b011-d13f29b08b1f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b506dd33-c918-43ab-a14d-7d28d8c38c72",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def inter_filler_dist(output_name):\n",
    "    ifd_metrics = pd.DataFrame(index=outcomes.index, columns=[\"mean_IFD\", \"std_IFD\", \"mean_IFD_norm\", \"mean_IFD_imputed\", \"std_IFD_imputed\"], dtype=float)\n",
    "\n",
    "    for split, pt_id in ifd_metrics.index:\n",
    "        ifds = []\n",
    "        for utt_num, row in adress_trans.loc[(split, pt_id)].iterrows():\n",
    "            if row[\"Speaker\"] == \"Patient\":     # skip provider speech\n",
    "                if len(row[output_name][\"detections\"]) > 1:     # can only compute IFD if there is more than one filler\n",
    "                    # get word spans for utterance\n",
    "                    doc = nlp(row[\"Transcript_clean\"])\n",
    "                    word_spans = [(token.text, token.idx, token.idx + len(token.text)) for token in doc if not (token.is_punct or token.is_space or token._.is_silence_tag or token._.is_inaudible_tag or token._.is_event_tag)]\n",
    "                    # print(\"word_spans\", word_spans)\n",
    "\n",
    "                    # get filler words indices\n",
    "                    filler_word_idxs = [word_spans.index((det[\"text\"], det[\"span\"][0], det[\"span\"][1])) for det in row[output_name][\"detections\"]]\n",
    "                    # print(\"filler_word_idxs:\", filler_word_idxs)\n",
    "\n",
    "                    # inter filler distance\n",
    "                    ifds.extend([filler_word_idxs[i+1] - filler_word_idxs[i] - 1 for i in range(len(filler_word_idxs) - 1)])\n",
    "                    # print(\"ifd\", ifds[-1])\n",
    "                    # break\n",
    "\n",
    "        ifd_metrics.loc[(split, pt_id), \"mean_IFD\"] = np.mean(ifds)\n",
    "        ifd_metrics.loc[(split, pt_id), \"std_IFD\"] = np.std(ifds)\n",
    "\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaler.fit(ifd_metrics.loc[\"train\", [\"mean_IFD\"]])\n",
    "    ifd_metrics[\"mean_IFD_norm\"] = scaler.transform(ifd_metrics[[\"mean_IFD\"]])\n",
    "    ifd_metrics[\"mean_IFD_imputed\"] = ifd_metrics[\"mean_IFD_norm\"].fillna(1.0)\n",
    "    ifd_metrics[\"std_IFD_imputed\"] = ifd_metrics[\"std_IFD\"].fillna(0)\n",
    "\n",
    "    return ifd_metrics                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "47cfdbc0-5b6f-422d-bf20-cefbaae3cd0d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_rows', None, 'display.max_colwidth', None):\n",
    "    outcomes[[\"kw_mean_IFD\", \"kw_std_IFD\", \"kw_mean_IFD_imp\", \"kw_std_IFD_imp\"]] = inter_filler_dist(\"keyword_dets\")[[\"mean_IFD\", \"std_IFD\", \"mean_IFD_imputed\", \"std_IFD_imputed\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "59a356c8-dcc6-4362-abf7-8b49b593d505",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "plt.violinplot(\n",
    "    (outcomes.loc[tst_ad_pts, \"kw_mean_IFD\"].dropna(),\n",
    "     outcomes.loc[tst_cn_pts, \"kw_mean_IFD\"].dropna(),\n",
    "     outcomes.loc[tst_ad_pts, \"kw_std_IFD\"].dropna(),\n",
    "     outcomes.loc[tst_cn_pts, \"kw_std_IFD\"].dropna()),\n",
    "    showmedians=True,\n",
    ")\n",
    "plt.xticks(range(1, 5), [\"Mean AD Group\", \"Mean Control Group\", \"Std AD Group\", \"Std Control Group\"], rotation=45, ha=\"right\")\n",
    "plt.ylabel(\"Inter Filler Distance\")\n",
    "plt.grid()\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cf326db3-df09-4c85-851f-7ec47aa5d098",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Analyze correlation between our metrics and the outcome variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "42661a20-d7cc-4cff-88bf-0ff2c92252bc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "metrics = [\n",
    "    \"gt_filler_rate\", \n",
    "    \"kw_filler_rate\", \n",
    "    \"kw_mean_IFD\", \n",
    "    \"kw_std_IFD\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a6b1dd6d-c709-4b1c-9a7b-3ca4e310ba48",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "for m in metrics:\n",
    "    ## score averages\n",
    "    mean_ad = outcomes.loc[tst_ad_pts, m].mean()\n",
    "    std_ad = outcomes.loc[tst_ad_pts, m].std()\n",
    "    mean_cn = outcomes.loc[tst_cn_pts, m].mean()\n",
    "    std_cn = outcomes.loc[tst_cn_pts, m].std()\n",
    "\n",
    "    ## correlation metrics\n",
    "    match = re.search(r\"(\\w+)_(\\w+)_IFD\", m)\n",
    "    if match:\n",
    "        # use imputed feature values for statistical tests\n",
    "        m = \"%s_%s_IFD_imp\" % match.groups()\n",
    "\n",
    "    res_ttest = ttest_ind(outcomes.loc[tst_pts, \"AD_dx\"], outcomes.loc[tst_pts, m])\n",
    "    res_mannw = mannwhitneyu(outcomes.loc[tst_pts, \"AD_dx\"], outcomes.loc[tst_pts, m])\n",
    "    res_auc   = roc_auc_score(outcomes.loc[tst_pts, \"AD_dx\"], outcomes.loc[tst_pts, m])\n",
    "\n",
    "    print(\"%s & %.2f (%.2f) & %.2f (%.2f) & %.2f (%s) & %.2f (%s) & %.2f \\\\\\\\\" % \n",
    "            (m,\n",
    "            mean_ad,\n",
    "            std_ad,\n",
    "            mean_cn,\n",
    "            std_cn,\n",
    "            res_ttest.statistic,\n",
    "            str(round(res_ttest.pvalue, 3)) if res_ttest.pvalue >= 0.001 else \"$<$0.001\", \n",
    "            res_mannw.statistic, \n",
    "            str(round(res_ttest.pvalue, 3)) if res_ttest.pvalue >= 0.001 else \"$<$0.001\",\n",
    "            res_auc)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "89551a0e-f610-4e2d-b7b1-3c10afc7458d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "outcomes[[\"kw_filler_rate\", \"kw_mean_IFD_imp\", \"kw_std_IFD_imp\"]].to_csv(\"filler_feats.csv\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "03_Filler_Speech",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
