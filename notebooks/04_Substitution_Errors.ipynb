{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1793cd3d-3489-404a-b957-f6ca2e0d6cbf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Detecting Substitution Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2917529a-0ba5-42a4-930d-5fd7e78fb584",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport data.adress\n",
    "%aimport utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5e67d695-263e-4656-9b37-449fc567d635",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from pprint import pprint\n",
    "# Evaluation\n",
    "from utils import evaluate\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from scipy.stats import ttest_ind, mannwhitneyu\n",
    "# Generative AI\n",
    "from openai import OpenAI\n",
    "from utils import llm_call\n",
    "import mlflow\n",
    "from mlflow.genai.scorers import Safety, scorer\n",
    "from mlflow.entities import Feedback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "69670ea8-82e9-42cb-a7b9-93388c3a9b1e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6f5dcc24-527b-4552-9d28-907f07aff9e6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from data.adress import load_transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "53af97ae-a28c-4b02-9bb9-38bc9dd6b896",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "adress_trans = load_transcripts()\n",
    "adress_trans = adress_trans[[\"Speaker\", \"Transcript\", \"Transcript_clean\", \"Phonological Error\", \"Semantic Error\", \"Neologistic Error\", \"Morphological Error\", \"Dysfluency\", \"Substitution Error\"]]\n",
    "\n",
    "# Count paraphasias\n",
    "adress_trans[\"num_word_errors\"] = adress_trans[\"Transcript\"].apply(lambda x: len(re.findall(r\"\\[*\\s[a-z:]+\\]\", x)))\n",
    "adress_trans[\"num_phonological\"] = adress_trans[\"Transcript\"].apply(lambda x: len(re.findall(r\"\\[*\\sp[:a-z]+\\]\", x)))\n",
    "adress_trans[\"num_semantic\"] = adress_trans[\"Transcript\"].apply(lambda x: len(re.findall(r\"\\[*\\ss[:a-z]+\\]\", x)))\n",
    "adress_trans[\"num_neologistic\"] = adress_trans[\"Transcript\"].apply(lambda x: len(re.findall(r\"\\[*\\sn[:a-z]+\\]\", x)))\n",
    "adress_trans[\"num_morphological\"] = adress_trans[\"Transcript\"].apply(lambda x: len(re.findall(r\"\\[*\\sm[:a-z]+\\]\", x)))\n",
    "adress_trans[\"num_dysfluency\"] = adress_trans[\"Transcript\"].apply(lambda x: len(re.findall(r\"\\[*\\sd[:a-z]+\\]\", x)))\n",
    "\n",
    "adress_trans.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c328fcb7-c465-485e-a4a7-815b62b8a23c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "trn_pt_utt_idx = (adress_trans.index.get_level_values(\"split\") == \"train\") & (adress_trans[\"Speaker\"] == \"Patient\")\n",
    "dev_pt_utt_idx = (adress_trans.index.get_level_values(\"split\") == \"dev\")   & (adress_trans[\"Speaker\"] == \"Patient\")\n",
    "tst_pt_utt_idx = (adress_trans.index.get_level_values(\"split\") == \"test\")  & (adress_trans[\"Speaker\"] == \"Patient\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f0df28a6-c8e4-4e45-9a2d-a05cfa042803",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "trn_pts = adress_trans.loc[\"train\"].index.get_level_values(\"ID\").unique().values\n",
    "dev_pts = adress_trans.loc[\"dev\"].index.get_level_values(\"ID\").unique().values\n",
    "tst_pts = adress_trans.loc[\"test\"].index.get_level_values(\"ID\").unique().values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "731f6556-9de8-4206-b9bf-8f0ee3bd1eae",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Baseline: MLM-Based Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f71a4869-c58f-414b-bbc0-ea6774b39dfb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b351b89b-3d6b-4d9e-bae9-98b10783a963",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "for output_json in os.listdir(\"mlm_outputs\"):\n",
    "    percentile = output_json.strip(\".json\").split(\"_\")[-1]\n",
    "\n",
    "    with open(f\"mlm_outputs/{output_json}\", \"r\") as f:\n",
    "        detections = json.load(f)\n",
    "        # pprint(detections)\n",
    "\n",
    "    adress_trans.loc[:, f\"mlm_det_{percentile}\"] = pd.NA\n",
    "\n",
    "    for det in detections:\n",
    "        if det[\"type\"] == \"paraphasia\":\n",
    "            split = [split for split, pt_list in zip([\"train\", \"dev\", \"test\"], [trn_pts, dev_pts, tst_pts]) if det[\"ID\"] in pt_list][0]\n",
    "            if adress_trans.loc[(split, det[\"ID\"], det[\"utt_num\"]), \"Speaker\"] == \"Patient\":\n",
    "                cur_dets = adress_trans.loc[(split, det[\"ID\"], det[\"utt_num\"]), f\"mlm_det_{percentile}\"]\n",
    "\n",
    "                if pd.isna(cur_dets):\n",
    "                    cur_dets = {\"detections\": []} \n",
    "\n",
    "                cur_dets[\"detections\"].append(det)\n",
    "                \n",
    "                adress_trans.at[(split, det[\"ID\"], det[\"utt_num\"]), f\"mlm_det_{percentile}\"] = cur_dets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "714893a1-cab1-441f-95ac-e9f7f3862533",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Performance on train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "64303466-0d40-45d3-84ec-b3fb73baf0a7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "for percentile in [90, 925, 95, 98, 99]:\n",
    "    true = adress_trans.loc[trn_pt_utt_idx, \"Substitution Error\"]\n",
    "    pred = adress_trans.loc[trn_pt_utt_idx, f\"mlm_det_{percentile}\"].apply(lambda x: len(x[\"detections\"]) > 0 if not pd.isna(x) else False).astype(int)\n",
    "    print(percentile, \"&\", evaluate(true, pred, return_latex=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "13822b42-b925-424f-a547-1a5bf563e490",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Best performing on test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7b897c07-ff55-41cd-9dd5-0876bd555c63",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "true = adress_trans.loc[tst_pt_utt_idx, \"Substitution Error\"]\n",
    "pred = adress_trans.loc[tst_pt_utt_idx, \"mlm_det_90\"].apply(lambda x: len(x[\"detections\"]) > 0 if not pd.isna(x) else False).astype(int)\n",
    "print(evaluate(true, pred, return_latex=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "04688e6a-c7cb-4760-9141-311b39d47fa7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## LLM-Based Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bab15eb4-8dcb-4fb5-b72f-4f64d9c58be4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2077f32f-65ae-4606-aafe-9c8823f99c94",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "mlflow_creds = mlflow.utils.databricks_utils.get_databricks_host_creds()\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=mlflow_creds.token,\n",
    "    base_url=f\"{mlflow_creds.host}/serving-endpoints\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3f2777e1-8d5c-464f-a6bd-4f4c8956c4de",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "datasets = {\n",
    "    \"train\": [],\n",
    "    \"dev\": [],\n",
    "    \"test\": []\n",
    "}\n",
    "\n",
    "for (split, pt_id), grp in adress_trans.groupby(level=[\"split\", \"ID\"]):\n",
    "    transcript = \"\\n\".join((grp.index.get_level_values(\"utt_num\").astype(str) + \": [\" + grp[\"Speaker\"] + \"] \" + grp[\"Transcript_clean\"]).values)\n",
    "    datasets[split].append({\n",
    "        \"split\": \"train\",\n",
    "        \"pt_id\": pt_id,\n",
    "        \"inputs\": {\"text\": transcript},\n",
    "        \"expectations\": {\"has_error\": {utt_num: row[\"Substitution Error\"] for (_, _, utt_num), row in grp.iterrows() if row[\"Speaker\"] == \"Patient\"}}\n",
    "    })\n",
    "\n",
    "# pprint(datasets[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c07a1756-c01e-4ce6-a151-d97b719e6cfd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "@scorer\n",
    "def correct(expectations, outputs):\n",
    "    det_utts = [det[\"utt_num\"] for det in outputs[\"detections\"]]\n",
    "\n",
    "    det_err = expectations[\"has_error\"]\n",
    "    val = 100 * sum([1 for utt_id in det_err if ((utt_id in det_utts) and det_err[utt_id]) or ((utt_id not in det_utts) and not det_err[utt_id])]) / len(det_err)\n",
    "\n",
    "    return Feedback(value=val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2015ff52-71d3-4d89-9ac2-04f5e49a26bb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def process_mlflow_outputs(result):\n",
    "    outputs = result.tables[\"eval_results\"][[\"response\", \"assessments\"]]\n",
    "    outputs[\"labels\"] = outputs[\"assessments\"].apply(lambda x: [a[\"value\"] for a in x if a[\"name\"] == \"has_error\"][0])\n",
    "    outputs[\"labels\"] = outputs[\"labels\"].apply(json.loads)\n",
    "    return outputs\n",
    "\n",
    "def extract_true_pred_from_ouputs(outputs):\n",
    "    outputs[\"utts_with_dets\"] = outputs[\"response\"].apply(lambda x: np.unique([det[\"utt_num\"] for det in x[\"detections\"]]))\n",
    "\n",
    "    true, pred = [], []\n",
    "    for i, row in outputs.iterrows():\n",
    "        true.extend(row[\"labels\"].values())\n",
    "        pred.extend([1 if int(utt_num) in row[\"utts_with_dets\"] else 0 for utt_num in row[\"labels\"]])\n",
    "    \n",
    "    return true, pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8d31be4c-3c15-41fb-b8ae-eadc23dbf636",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "with pd.option_context(\"display.max_colwidth\", None):\n",
    "    print(adress_trans.loc[(adress_trans.index.get_level_values(0) == \"dev\") & (adress_trans[\"Phonological Error\"] == 1), [\"Transcript\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "82a50b10-2011-4ff3-b6f7-bde36ab3c04e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "with pd.option_context(\"display.max_colwidth\", None):\n",
    "    print(adress_trans.loc[(\"dev\", \"S082\"), [\"Speaker\", \"Transcript_clean\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "23c4066a-04e4-4bd1-8c38-eb46d788d1f5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Explore different prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9931f132-0150-4659-896f-07747e6bb4e8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# version = \"1_3\"\n",
    "# prompt = '''# INSTRUCTIONS\n",
    "# You are a neurologist analyzing a patient's speech sample for signs of cognitive impairment. \n",
    "\n",
    "# Your task is to identify all substitution errors in a patient's speech provided in the input below.\n",
    "\n",
    "# ### Definition\n",
    "# Substitution errors occur when a person involuntarily replaces their intended word with an unintended word while speaking. Focus on detecting the following five substitution errors types:\n",
    "# - Phonemic paraphasias, where sounds within the intended word are added, dropped, substituted, or rearranged (e.g., saying ``papple'' for ``apple''). This does **not** include words with dropped sounds if the usage represents a common, informal speaking style rather than a clinical error (e.g., \"gettin\" for \"getting\").\n",
    "# - Semantic paraphasias, where the intended word is substituted entirely with another real word (e.g., saying ``cat'' for ``dog'').\n",
    "# - Neologisms, where the entire intended word is substituted with a non-word (e.g., saying \"foundament\" for \"foundation\").\n",
    "# - Morphological errors, where the intended word is used in the incorrect form, such as the wrong number (e.g., saying \"child\" for \"children\") or tense (e.g., saying \"walked\" for \"walk\").\n",
    "# - Intra-word dysfluencies, where the production of the intended word is disrupted by an inserted sound (e.g., saying \"beuhcause\" for \"because\").\n",
    "\n",
    "# Only flag single words that are clinically significant substitution errors and use the surrounding utterances to better understand the context of any given word. \n",
    "\n",
    "# ### Output Format\n",
    "# Your output must be a single JSON object with a single key \"detections\" whose value is an array of JSON objects. Each object in the array represents one detected substitution error and must have the following keys-value pairs:\n",
    "# - \"type\": \"substitution error\".\n",
    "# - \"utt_num\": The number of the utterance in which the error occurs.\n",
    "# - \"text\": The verbatim text of the substition error.\n",
    "# - \"span\": The character span for the \"text\" in the \"utt_num\"-th utterance.\n",
    "# - \"justification\": A brief explanation of why the \"text\" is a substitution error within its specific context.\n",
    "\n",
    "# # INPUT\n",
    "# {input_text}\n",
    "# '''\n",
    "\n",
    "# version = \"1_5_fewshot\"\n",
    "# fs_prompt = '''# INSTRUCTIONS\n",
    "# You are a neurologist analyzing a patient's speech sample for signs of cognitive impairment. \n",
    "\n",
    "# Your task is to identify all substitution errors in a patient's speech provided in the input below.\n",
    "\n",
    "# ### Definition\n",
    "# Substitution errors occur when a person involuntarily replaces their intended word with an unintended word while speaking. Focus on detecting the following five substitution errors types:\n",
    "# - Phonemic paraphasias, where sounds within the intended word are added, dropped, substituted, or rearranged (e.g., saying ``papple'' for ``apple''). \n",
    "# - Semantic paraphasias, where the intended word is substituted entirely with another real word (e.g., saying ``cat'' for ``dog'').\n",
    "# - Neologisms, where the entire intended word is substituted with a non-word (e.g., saying \"foundament\" for \"foundation\").\n",
    "# - Morphological errors, where the intended word is used in the incorrect form, such as the wrong number (e.g., saying \"child\" for \"children\") or tense (e.g., saying \"walked\" for \"walk\").\n",
    "# - Intra-word dysfluencies, where the production of the intended word is disrupted by an inserted sound (e.g., saying \"beuhcause\" for \"because\").\n",
    "\n",
    "# Only flag single words that are clinically significant substitution errors and use the surrounding utterances to better understand the context of any given word. **Focus on errors that seem unlikely to be caused by common, informal speaking patterns.**\n",
    "\n",
    "# ### Output Format\n",
    "# Your output must be a single JSON object with a single key \"detections\" whose value is an array of JSON objects. Each object in the array represents one detected substitution error and must have the following keys-value pairs:\n",
    "# - \"type\": \"substitution error\".\n",
    "# - \"utt_num\": The number of the utterance in which the error occurs.\n",
    "# - \"text\": The verbatim text of the substition error.\n",
    "# - \"span\": The character span for the \"text\" in the \"utt_num\"-th utterance.\n",
    "# - \"justification\": A brief explanation of why the \"text\" is a substitution error within its specific context.\n",
    "\n",
    "# # EXAMPLES\n",
    "# **Input**\n",
    "# 1. Patient: well there's a mother standing there uh uh washing the dishes an the sink is overspilling .\n",
    "# 2. Patient: an uh the window's open .\n",
    "# 3. Patient: and outside the window there's a walk with a c curved walk with a garden .\n",
    "\n",
    "# **Correct Output**\n",
    "# {{\n",
    "#     \"detections\": [\n",
    "#         {{\"type\": \"substitution error\", \"utt_num\": 1, \"text\": \"overspilling\", \"span\": [,], \"justification\": \"The word 'overspilling' is a semantic paraphasia where the intended word was 'overflowing'.}},\n",
    "#     ]\n",
    "# }}\n",
    "\n",
    "# **Input**\n",
    "# 1. Provider: [laughs] well is there anything else that you can think of ?\n",
    "# 2. Patient: but mostly uh is I I have uh not not so much trouble uh in I d it uh uh looking at a thing at it uh as um s um am an imarriage but not [silence] but not getting anything that you'll want s want [inaudible] .\n",
    "\n",
    "# **Correct Output**\n",
    "# {{\n",
    "#     \"detections\": [\n",
    "#         {{\"type\": \"substitution error\", \"utt_num\": 1, \"text\": \"imarriage\", \"span\": [,], \"justification\": \"The word 'imarriage' is a phonemic paraphasia where the intended word was 'image'.}},\n",
    "#     ]\n",
    "# }}\n",
    "\n",
    "# # INPUT\n",
    "# {input_text}\n",
    "# '''\n",
    "\n",
    "\n",
    "version = \"1_6\"\n",
    "prompt = '''# INSTRUCTIONS\n",
    "You are a neurologist analyzing a patient's speech sample for signs of cognitive impairment. \n",
    "\n",
    "Your task is to identify all substitution errors in a patient's speech provided in the input below.\n",
    "\n",
    "### Definition\n",
    "Substitution errors occur when a person involuntarily replaces their intended word with an unintended word while speaking. Focus on detecting the following five substitution errors types:\n",
    "- Phonemic paraphasias, where sounds within the intended word are added, dropped, substituted, or rearranged (e.g., saying ``papple'' for ``apple''). \n",
    "- Semantic paraphasias, where the intended word is substituted entirely with another real word (e.g., saying ``cat'' for ``dog'').\n",
    "- Neologisms, where the entire intended word is substituted with a non-word (e.g., saying \"foundament\" for \"foundation\").\n",
    "- Morphological errors, where the intended word is used in the incorrect form, such as the wrong number (e.g., saying \"child\" for \"children\") or tense (e.g., saying \"walked\" for \"walk\").\n",
    "- Intra-word dysfluencies, where the production of the intended word is disrupted by an inserted sound (e.g., saying \"beuhcause\" for \"because\").\n",
    "\n",
    "Only flag single words that are clinically significant substitution errors and use the surrounding utterances to better understand the context of any given word.\n",
    "\n",
    "### Output Format\n",
    "Your output must be a single JSON object with a single key \"detections\" whose value is an array of JSON objects. Each object in the array represents one detected substitution error and must have the following keys-value pairs:\n",
    "- \"type\": \"substitution error\".\n",
    "- \"utt_num\": The number of the utterance in which the error occurs.\n",
    "- \"text\": The verbatim text of the substition error.\n",
    "- \"span\": The character span for the \"text\" in the \"utt_num\"-th utterance.\n",
    "- \"justification\": A brief explanation of why the \"text\" is a substitution error within its specific context.\n",
    "\n",
    "# INPUT\n",
    "{input_text}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4e8c2b29-d756-409f-b056-92720628ccda",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "fn = lambda text: llm_call(client, \"openai_gpt_4o\", None, prompt.format(input_text=text), {\"type\": \"json_object\"})\n",
    "\n",
    "with mlflow.start_run(run_name=f\"gpt_trn_pV{version}\"): \n",
    "    gpt_dets_trn = mlflow.genai.evaluate(\n",
    "        data=datasets[\"train\"],\n",
    "        predict_fn=fn,\n",
    "        scorers=[correct]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ceec059b-a561-4a7c-a4b4-dbd3f0e616e7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "outputs = process_mlflow_outputs(gpt_dets_trn)\n",
    "outputs.to_pickle(f\"llm_outputs/sub_err_trn_gpt_pV{version}\")\n",
    "\n",
    "true, pred = extract_true_pred_from_ouputs(outputs)\n",
    "print(evaluate(true, pred, return_latex=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5dbd7c10-01fd-4560-8458-3915e02d35c5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "0.112 & 0.714 & 0.194 & 0.790 & 0.754 \\\\\n",
    "0.118 & 0.657 & 0.200 & 0.814 & 0.739 \\\\\n",
    "0.121 & 0.600 & 0.201 & 0.831 & 0.720 \\\\\n",
    "0.152 & 0.714 & 0.251 & 0.850 & 0.784 \\\\\n",
    "0.152 & 0.714 & 0.251 & 0.850 & 0.784 \\\\\n",
    "0.117 & 0.600 & 0.196 & 0.826 & 0.717 \\\\\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "149f47b4-9009-405f-afa1-424b6104690c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##### Evaluate the best configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e7a0367a-330c-46f5-8fab-ea1d714b509b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "fn = lambda text: llm_call(client, \"openai_gpt_4o\", None, prompt.format(input_text=text), {\"type\": \"json_object\"})\n",
    "\n",
    "with mlflow.start_run(run_name=f\"gpt_eval_tst_pV{version}\") as run:\n",
    "    gpt_dets_tst = mlflow.genai.evaluate(\n",
    "        predict_fn=fn,\n",
    "        data=datasets[\"test\"],\n",
    "        scorers=[correct]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cbdeb153-62f0-48e8-8470-946fd88719d0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "outputs = process_mlflow_outputs(gpt_dets_tst)\n",
    "outputs.to_pickle(f\"llm_outputs/sub_err_tst_gpt_pV{version}\")\n",
    "\n",
    "true, pred = extract_true_pred_from_ouputs(outputs)\n",
    "print(evaluate(true, pred, return_latex=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "505f96c2-b1a9-4a7a-b795-d91272cd2e3f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Summary metrics for paraphasia detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "317ae7ef-1332-4d21-9214-1e3855053eb9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from data.adress import load_outcomes\n",
    "from utils import create_custom_nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "64a60dfa-2cae-43fd-acfc-8b3fd8de289d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "outcomes = load_outcomes()\n",
    "outcomes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "877c3a5d-fc7b-4804-906a-d5dec5f1894d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "trn_pts = outcomes.loc[(outcomes.index.get_level_values(\"split\") == \"train\")].index.values\n",
    "trn_ad_pts = outcomes.loc[(outcomes.index.get_level_values(\"split\") == \"train\") & (outcomes[\"AD_dx\"] == 1)].index.values\n",
    "trn_cn_pts = outcomes.loc[(outcomes.index.get_level_values(\"split\") == \"train\") & (outcomes[\"AD_dx\"] == 0)].index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c88ea34e-aaed-4f11-91a7-8a80d63d1b20",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "tst_pts = outcomes.loc[(outcomes.index.get_level_values(\"split\") == \"test\")].index.values\n",
    "tst_ad_pts = outcomes.loc[(outcomes.index.get_level_values(\"split\") == \"test\") & (outcomes[\"AD_dx\"] == 1)].index.values\n",
    "tst_cn_pts = outcomes.loc[(outcomes.index.get_level_values(\"split\") == \"test\") & (outcomes[\"AD_dx\"] == 0)].index.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "88a73e0d-ccd4-4b2f-a8c7-1e068c6d1e74",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Paraphasia Rate** = Total number of detected paraphasias / Total number of words spoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5fbf8b71-16ae-4140-9092-fe5706f365eb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "nlp = create_custom_nlp()\n",
    "\n",
    "def compute_paraphasia_rate(outputs):\n",
    "    num = outputs.apply(lambda x: len(x[\"detections\"]) if not pd.isna(x) else 0).groupby(level=(\"split\", \"ID\")).sum()\n",
    "    den = adress_trans.apply(lambda x: sum([1 for token in nlp(x[\"Transcript_clean\"]) if not (token.is_punct or token.is_space or token._.is_silence_tag or token._.is_inaudible_tag or token._.is_event_tag)]) if x[\"Speaker\"] == \"Patient\" else 0, axis=1).groupby(level=(\"split\", \"ID\")).sum()\n",
    "    return 100 * num / den"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2985c81f-2f9f-4447-92e5-ebc61a2f2efa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# outcomes[\"gt_paraphasia_rate\"] = compute_paraphasia_rate(adress_trans[\"num_paraphasias\"].apply(lambda x: {\"detections\": [0] * x}))\n",
    "# outcomes[\"gt_phonological_rate\"] = compute_paraphasia_rate(adress_trans[\"num_phonological\"].apply(lambda x: {\"detections\": [0] * x}))\n",
    "# outcomes[\"gt_semantic_rate\"] = compute_paraphasia_rate(adress_trans[\"num_semantic\"].apply(lambda x: {\"detections\": [0] * x}))\n",
    "# outcomes[\"gt_neologistic_rate\"] = compute_paraphasia_rate(adress_trans[\"num_neologistic\"].apply(lambda x: {\"detections\": [0] * x}))\n",
    "# outcomes[\"gt_morphological_rate\"] = compute_paraphasia_rate(adress_trans[\"num_morphological\"].apply(lambda x: {\"detections\": [0] * x}))\n",
    "# outcomes[\"gt_dysfluency_rate\"] = compute_paraphasia_rate(adress_trans[\"num_dysfluency\"].apply(lambda x: {\"detections\": [0] * x}))\n",
    "outcomes[\"mlm_sub_error_rate\"] = compute_paraphasia_rate(adress_trans[\"mlm_det_90\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7e288026-1e1c-495d-8880-e0c930fa11ea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Inter-Paraphasia Distance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "868a1124-1acd-4b8b-a5df-905fa0cd01be",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cb0edf7a-1fba-436e-b811-632f96abcecd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def inter_sub_error_dist(output_name):\n",
    "    ISED_metrics = pd.DataFrame(index=outcomes.index, columns=[\"mean_ISED\", \"std_ISED\", \"mean_ISED_norm\", \"mean_ISED_imputed\", \"std_ISED_imputed\"], dtype=float)\n",
    "\n",
    "    for split, pt_id in ISED_metrics.index:\n",
    "        ISEDs = []\n",
    "        for utt_num, row in adress_trans.loc[(split, pt_id)].iterrows():\n",
    "            if row[\"Speaker\"] == \"Patient\":     # skip provider speech\n",
    "                if not pd.isna(row[output_name]) and len(row[output_name][\"detections\"]) > 1:   # can only compute ISED if there is more than one error\n",
    "                    # get word spans for utterance\n",
    "                    doc = nlp(row[\"Transcript_clean\"])\n",
    "                    word_spans = [(token.text, token.idx, token.idx + len(token.text)) for token in doc if not (token.is_punct or token.is_space or token._.is_silence_tag or token._.is_inaudible_tag or token._.is_event_tag)]\n",
    "                    # print(\"word_spans\", word_spans)\n",
    "\n",
    "                    # get substitution error words indices\n",
    "                    paraphasia_word_idxs = [word_spans.index((det[\"text\"], det[\"span\"][0], det[\"span\"][1])) for det in row[output_name][\"detections\"]]\n",
    "                    # print(\"paraphasia_word_idxs:\", paraphasia_word_idxs)\n",
    "\n",
    "                    # inter paraphasia distance\n",
    "                    ISEDs.extend([paraphasia_word_idxs[i+1] - paraphasia_word_idxs[i] - 1 for i in range(len(paraphasia_word_idxs) - 1)])\n",
    "                    # print(\"ISED\", ISEDs[-1])\n",
    "                    # break\n",
    "\n",
    "        ISED_metrics.loc[(split, pt_id), \"mean_ISED\"] = np.mean(ISEDs)\n",
    "        ISED_metrics.loc[(split, pt_id), \"std_ISED\"] = np.std(ISEDs)\n",
    "\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaler.fit(ISED_metrics.loc[\"train\", [\"mean_ISED\"]])\n",
    "    with open(\"ISED_scaler.pkl\", \"wb\") as f:\n",
    "        pickle.dump(scaler, f)\n",
    "\n",
    "    ISED_metrics[\"mean_ISED_norm\"] = scaler.transform(ISED_metrics[[\"mean_ISED\"]])\n",
    "    ISED_metrics[\"mean_ISED_imputed\"] = ISED_metrics[\"mean_ISED_norm\"].fillna(1.0)\n",
    "    ISED_metrics[\"std_ISED_imputed\"] = ISED_metrics[\"std_ISED\"].fillna(0)\n",
    "\n",
    "    return ISED_metrics                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c53c4c36-10cb-4988-afe2-46b3d7d9db35",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_rows', None, 'display.max_colwidth', None):\n",
    "    outcomes[[\"mlm_mean_ISED\", \"mlm_std_ISED\", \"mlm_mean_ISED_imp\", \"mlm_std_ISED_imp\"]] = inter_sub_error_dist(\"mlm_det_90\")[[\"mean_ISED\", \"std_ISED\", \"mean_ISED_imputed\", \"std_ISED_imputed\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0849e7ca-967e-4810-b348-d667fafd55e5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Test for statistically significant differences in feature values between the AD and non-AD groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "470ff367-2c46-450e-983f-a84ff634bad1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Generates the rows of Table 10 and 11\n",
    "def analysis(split_idx, split_ad, split_cn, metrics):\n",
    "    for m in metrics:\n",
    "        ## score averages\n",
    "        mean_ad = outcomes.loc[split_ad, m].mean()\n",
    "        std_ad = outcomes.loc[split_ad, m].std()\n",
    "        mean_cn = outcomes.loc[split_cn, m].mean()\n",
    "        std_cn = outcomes.loc[split_cn, m].std()\n",
    "\n",
    "        ## correlation metrics\n",
    "        match = re.search(r\"(\\w+)_(\\w+)_ISED\", m)\n",
    "        if match:\n",
    "            # use imputed feature values for statistical tests\n",
    "            m = \"%s_%s_ISED_imp\" % match.groups()\n",
    "\n",
    "        res_ttest = ttest_ind(outcomes.loc[split_idx, \"AD_dx\"], outcomes.loc[split_idx, m])\n",
    "        res_mannw = mannwhitneyu(outcomes.loc[split_idx, \"AD_dx\"], outcomes.loc[split_idx, m])\n",
    "        res_auc   = roc_auc_score(outcomes.loc[split_idx, \"AD_dx\"], outcomes.loc[split_idx, m])\n",
    "\n",
    "        print(\"%s & %.2f (%.2f) & %.2f (%.2f) & %.2f (%s) & %.2f (%s) & %.2f \\\\\\\\\" % \n",
    "                (m,\n",
    "                mean_ad,\n",
    "                std_ad,\n",
    "                mean_cn,\n",
    "                std_cn,\n",
    "                res_ttest.statistic,\n",
    "                str(round(res_ttest.pvalue, 3)) if res_ttest.pvalue >= 0.001 else \"$<$0.001\", \n",
    "                res_mannw.statistic, \n",
    "                str(round(res_ttest.pvalue, 3)) if res_ttest.pvalue >= 0.001 else \"$<$0.001\",\n",
    "                res_auc)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ce4f5021-51d6-430d-be24-b5ba2ef6627c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "mets = [\n",
    "    # \"gt_paraphasia_rate\",\n",
    "    # \"gt_phonological_rate\",\n",
    "    # \"gt_semantic_rate\",\n",
    "    # \"gt_neologistic_rate\",\n",
    "    # \"gt_morphological_rate\",\n",
    "    # \"gt_dysfluency_rate\",\n",
    "    \"mlm_sub_error_rate\",\n",
    "    \"mlm_mean_ISED\", \n",
    "    \"mlm_std_ISED\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "886e774b-36c4-4150-94de-517b20ee7a5e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "analysis(trn_pts, trn_ad_pts, trn_cn_pts, mets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5b5d4ded-b5e5-4ff5-a64c-cb11c27261fa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "outcomes[[\"mlm_sub_error_rate\", \"mlm_mean_ISED_imp\", \"mlm_std_ISED_imp\"]].to_csv(\"feature_data/sub_error_feats.csv\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "04_Substitution_Errors",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
