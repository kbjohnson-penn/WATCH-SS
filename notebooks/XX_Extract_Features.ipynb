{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c3e57e47-4840-4b1e-a2e7-a787633c2764",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade openai\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e9bb8ebe-c671-4841-8a81-d4f5c343297e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport data.load_adress_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2640c906-510d-4beb-a303-002fe3f5fd08",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import pandas as pd\n",
    "import time\n",
    "from openai import OpenAI\n",
    "from tqdm.notebook import tqdm\n",
    "from utils import num_tokens_from_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e326eeb7-b36d-4552-952a-4ddde3573d2c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "model       = \"gpt-4o\"\n",
    "model_name  = \"openai_gpt_4o\"\n",
    "temperature = 0.0\n",
    "top_p       = 1.0\n",
    "tpm         = 1e6\n",
    "rpm         = 6150\n",
    "chunk_lines = 10\n",
    "\n",
    "p_short_responses = (\n",
    "    \"Identify all instances where the patient speaks in short utterances that may indicate cognitive impairment (e.g., patient responds to \\\"How are you feeling?\\\" with a one word answer \\\"Okay.\\\") in the following transcript:\\n\\n\"\n",
    "    \"{}\\n\\n\"\n",
    "    \"Return a bullet list of the short utterances. If there are none, return \\\"None\\\".\"\n",
    ")\n",
    "\n",
    "p_filler_speech = (\n",
    "    \"Identify all filler words, phrases, or sounds that indicate possible cognitive impairment (e.g., \\\"uh\\\", \\\"um\\\", and \\\"ah\\\") from the following utterance:\\n\\n\"\n",
    "    \"{}\\n\\n\"\n",
    "    \"Return a bullet list of relevant fillers. If there are none, return \\\"None\\\".\"\n",
    ")\n",
    "\n",
    "p_repetitive_speech = (\n",
    "    \"Identify all instances where the patientâ€™s speech shows repetition that may indicate cognitive impairment in the following transcript:\\n\\n\"\n",
    "    \"{}\\n\\n\"\n",
    "    \"Return a bullet list of the repeated content exactly as spoken. If there are none, return \\\"None\\\".\"\n",
    ")\n",
    "\n",
    "p_vague_speech = (\n",
    "    \"Identify all vague words or phrases that indicate possible cognitive impairment (e.g., \\\"you know\\\" or \\\"that thing\\\") from the following transcript:\"\n",
    "    \"{}\\n\\n\"\n",
    "    \"Return a bullet list of vague words or phrases exactly as spoken. If none are present, return \\\"None\\\".\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7b273e03-3ddd-4b9b-84e4-07b626150702",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def extract_features(data, prompt, model, model_name, temperature, top_p, tpm, rpm):\n",
    "    DATABRICKS_TOKEN = dbutils.notebook.entry_point.getDbutils().notebook().getContext().apiToken().get()\n",
    "\n",
    "    client = OpenAI(\n",
    "        api_key=DATABRICKS_TOKEN,\n",
    "        base_url=\"https://adb-2035410508966251.11.azuredatabricks.net/serving-endpoints\"\n",
    "    )\n",
    "\n",
    "    t_per_token = 60 / tpm\n",
    "    t_per_request = 60 / rpm\n",
    "\n",
    "    with tqdm(total=data.shape[0]) as pbar:\n",
    "        for idx, row in data.iterrows():\n",
    "            messages = [{\"role\": \"user\", \"content\": prompt.format(row[\"Query\"])}]\n",
    "            data.loc[idx, \"query_tokens\"] = num_tokens_from_messages(messages, model)\n",
    "\n",
    "            # send the query\n",
    "            result = client.chat.completions.create(\n",
    "                model=model_name,\n",
    "                messages=messages,\n",
    "                temperature=temperature,\n",
    "                top_p=top_p\n",
    "            )\n",
    "\n",
    "            # log the response\n",
    "            data.loc[idx, \"response\"] = result.choices[0].message.content\n",
    "            data.loc[idx, \"response_tokens\"] = result.usage.completion_tokens\n",
    "            pbar.update(1)\n",
    "\n",
    "            # sleep to abide by rate limit\n",
    "            delay = max(t_per_request, (data.loc[idx, \"query_tokens\"] + data.loc[idx, \"response_tokens\"]) * t_per_token)\n",
    "            time.sleep(delay)\n",
    "            \n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "18e8df72-fb16-4f72-88a7-2049adbd93e5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8118045d-17f0-4499-954c-a19814f7c5aa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import data.load_adress_data\n",
    "\n",
    "transcripts = data.load_adress_data.load_adress_CHAT_transcripts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a2abd202-a92d-49d4-8ad8-a62a1048f033",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# filler speech\n",
    "data = transcripts.loc[transcripts[\"Speaker\"] == \"Patient\", \"Utterance\"].to_frame(name=\"Query\")\n",
    "data = extract_features(data, p_filler_speech, model, model_name, temperature, top_p, tpm, rpm)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6195ba17-ec29-45a4-a019-0bf76ff2b477",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "data.to_excel(\"adress_filler_speech.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "55b1d634-9ffe-4548-b2b9-ac62b6e7c959",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# repetitive speech\n",
    "data2 = transcripts[\"Utterance\"].groupby((pd.Series(range(transcripts.shape[0])) // chunk_lines).values).agg(lambda col: \"\\n\".join(col)).to_frame(name=\"Query\")\n",
    "data2 = extract_features(data2, p_repetitive_speech, model, model_name, temperature, top_p, tpm, rpm)\n",
    "data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "693bea64-2666-4481-8dad-b5fc97818441",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "data2.to_excel(\"adress_repetitive_speech.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d22f9310-a506-4655-83b6-53e959488443",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# short responses\n",
    "data3 = transcripts[\"Utterance\"].groupby((pd.Series(range(transcripts.shape[0])) // chunk_lines).values).agg(lambda col: \"\\n\".join(col)).to_frame(name=\"Query\")\n",
    "data3 = extract_features(data3, p_short_responses, model, model_name, temperature, top_p, tpm, rpm)\n",
    "data3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c3b13b05-cd90-468a-980d-e4105f512b9a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "data3.to_excel(\"adress_short_responses.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4d32153f-c495-4999-8a3f-968ba0a69553",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# vague speech\n",
    "data4 = transcripts[\"Utterance\"].groupby((pd.Series(range(transcripts.shape[0])) // chunk_lines).values).agg(lambda col: \"\\n\".join(col)).to_frame(name=\"Query\")\n",
    "data4 = extract_features(data4, p_vague_speech, model, model_name, temperature, top_p, tpm, rpm)\n",
    "data4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c8db152b-4644-4584-b3e2-9a7d333eee8b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "data4.to_excel(\"adress_vague_speech.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "XX_Extract_Features",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
