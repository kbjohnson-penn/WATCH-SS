{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328de697",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pylangacq pydub moviepy ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1597007b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pylangacq\n",
    "import re\n",
    "import ast\n",
    "from pydub import AudioSegment\n",
    "from pydub.silence import detect_silence\n",
    "from moviepy import VideoFileClip\n",
    "import ffmpeg\n",
    "import os\n",
    "import tempfile\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f848c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_audio(audio_file, min_silence_len, silence_thresh):\n",
    "    if audio_file.lower().endswith(\".wav\"):\n",
    "        audio_segment = AudioSegment.from_file(audio_file, format=\"wav\")\n",
    "    elif audio_file.lower().endswith(\".mp4\"):\n",
    "        sys.stdout = open(os.devnull, 'w')\n",
    "        video = VideoFileClip(audio_file)\n",
    "        sys.stdout = sys.__stdout__\n",
    "\n",
    "        temp_dir = tempfile.gettempdir()\n",
    "        if not os.access(temp_dir, os.W_OK):\n",
    "            raise PermissionError(f\"Write access is not allowed for temp directory: {temp_dir}\")\n",
    "        \n",
    "        try:\n",
    "            with tempfile.NamedTemporaryFile(suffix=\".wav\", dir=temp_dir, delete=False) as temp_audio_file:\n",
    "                audio = video.audio\n",
    "                audio.write_audiofile(temp_audio_file.name, codec='pcm_s16le')\n",
    "                audio_segment = AudioSegment.from_file(temp_audio_file.name, format=\"wav\")\n",
    "\n",
    "        except Exception as e:\n",
    "            raise OSError(f\"Error processing audio: {str(e)}\")\n",
    "    else:\n",
    "        raise ValueError(\"Use a file type that contains audio.\")\n",
    "    \n",
    "    silences = detect_silence(\n",
    "        audio_segment,\n",
    "        min_silence_len=min_silence_len if min_silence_len is not None else 2000, # 2 seconds\n",
    "        silence_thresh=silence_thresh if silence_thresh is not None else -45 # default silence threshold\n",
    "    )\n",
    "    \n",
    "    return silences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d40d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experimenting with different parameters\n",
    "min_silence_lens = [10] # list of integers\n",
    "silence_threshes = [-55] # list of integers\n",
    "f_df = pd.DataFrame()\n",
    "\n",
    "for e, (min_sil_len, sil_thresh) in enumerate(zip(min_silence_lens, silence_threshes)):\n",
    "    print(f\"{e+1}/{len(min_silence_lens)}\")\n",
    "    silences = []\n",
    "    for aud in tqdm(): # Paths to audio files\n",
    "        silences += [process_audio(aud, min_silence_len=min_sil_len, silence_thresh=sil_thresh)]\n",
    "    \n",
    "    f_df[f\"min_silence_len_{min_sil_len}_silence_thresh_{sil_thresh}\"] = silences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7202e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len of audio for just the patient\n",
    "def compute_patient_speaking_time(transcripts):\n",
    "    audio_lens = []\n",
    "    for pt in transcripts.patient_id.unique():\n",
    "        pt_df = transcripts.query(f\"patient_id == '{pt}' and Speaker == 'Patient'\")\n",
    "        audio_sum = 0\n",
    "        for idx in pt_df.index.tolist():\n",
    "            audio_sum += pt_df.loc[idx][\"T_end_ms\"] - pt_df.loc[idx][\"T_start_ms\"]\n",
    "        audio_lens.append(audio_sum)\n",
    "\n",
    "    return audio_lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec474312",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len of audio for full session\n",
    "def compute_full_session_time(transcripts):\n",
    "    audio_lens = []\n",
    "    for pt in transcripts.patient_id.unique():\n",
    "        audio_lens.append(transcripts.query(f\"patient_id == '{pt}'\")[\"T_end_ms\"].max())\n",
    "    \n",
    "    return audio_lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0894c1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(y_pred_binary, y_true_binary):\n",
    "    accuracy = accuracy_score(y_true_binary, y_pred_binary)\n",
    "    precision = precision_score(y_true_binary, y_pred_binary, zero_division=0)\n",
    "    recall = recall_score(y_true_binary, y_pred_binary, zero_division=0)\n",
    "    f1 = f1_score(y_true_binary, y_pred_binary, zero_division=0)\n",
    "    auc = roc_auc_score(y_true_binary, y_pred_binary)\n",
    "    \n",
    "    # Calculate False Positive Rate (FPR)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true_binary, y_pred_binary).ravel()\n",
    "    fpr = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
    "\n",
    "    return accuracy, precision, recall, f1, auc, fpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3294fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_scores(transcript, silences, col):\n",
    "    transcript['pydub_silences'] = 0\n",
    "    transcripts_df = transcript.copy()\n",
    "    patient_ids = transcripts_df.patient_id.unique()\n",
    "\n",
    "    for e, p_id in enumerate(patient_ids):\n",
    "        appended_silences = set()\n",
    "        # Filter rows for the current patient\n",
    "        temp_df = transcripts_df[transcripts_df['patient_id'] == p_id]\n",
    "        s = ast.literal_eval(silences.iloc[e])\n",
    "        \n",
    "        for i in range(len(temp_df)):\n",
    "            start_ms = temp_df['T_start_ms'].iloc[i]\n",
    "            end_ms = temp_df['T_end_ms'].iloc[i]\n",
    "            silence_count = 0\n",
    "            # Count silences within or partially overlapping the time range\n",
    "            for sil in s:\n",
    "                silence_tuple = tuple(sil)\n",
    "                if silence_tuple in appended_silences:\n",
    "                    continue\n",
    "                # Check for any overlap between silence and time range\n",
    "                if sil[0] <= end_ms and sil[1] >= start_ms:\n",
    "                    appended_silences.add(silence_tuple)\n",
    "                    silence_count += 1\n",
    "            \n",
    "            transcripts_df.loc[temp_df.index[i], 'pydub_silences'] = silence_count\n",
    "\n",
    "    # Convert to binary classification: silence > 0 -> 1, else 0\n",
    "    transcripts_df[\"pydub_silences\"] = (transcripts_df[\"pydub_silences\"] > 0).astype(int)\n",
    "    accuracy, precision, recall, f1, auc, fpr = calculate_metrics(transcripts_df[\"pydub_silences\"], transcripts_df[\"Speech delays\"])\n",
    "\n",
    "    return pd.DataFrame({'Accuracy': [accuracy], 'Precision': [precision], 'Recall': [recall], 'F1': [f1], 'AUC': [auc], 'FPR': [fpr], 'Parameters': [col]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1afebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe with features for different silence lengths\n",
    "def min_silence_len_sets(df, sil_len_thresh_ms, min_silence_col):\n",
    "    all_sil_df = pd.DataFrame()\n",
    "    all_sil_df[min_silence_col] = df[min_silence_col]\n",
    "    all_sil_df[f\"min_silence_len_{sil_len_thresh_ms}_silence_thresh_-55\"] = df[min_silence_col].apply(lambda x: 0)\n",
    "\n",
    "    for i, sil_ts in enumerate(all_sil_df[min_silence_col]):\n",
    "        sil_ts_list = ast.literal_eval(sil_ts)\n",
    "        val_sils = []\n",
    "        for start, end in sil_ts_list:\n",
    "            if end - start >= sil_len_thresh_ms:\n",
    "                val_sils.append([start, end])\n",
    "        all_sil_df.loc[i, f\"min_silence_len_{sil_len_thresh_ms}_silence_thresh_-55\"] = str(val_sils)\n",
    "\n",
    "    return all_sil_df[[f\"min_silence_len_{sil_len_thresh_ms}_silence_thresh_-55\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfcac1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get detected silences where detected silence overlaps with labeled speech delay\n",
    "def process_silences(df, all_sil_df):\n",
    "    silence_lengths = [10] + list(range(100, 10_100, 50))\n",
    "    val_sil_df = pd.DataFrame()\n",
    "\n",
    "    for l in silence_lengths:\n",
    "        valid_silences = []\n",
    "\n",
    "        for i, id in enumerate(df.patient_id.unique()):\n",
    "            test_df = df[df[\"patient_id\"] == id]\n",
    "            if i < len(all_sil_df):\n",
    "                test_silences = ast.literal_eval(all_sil_df[f\"min_silence_len_{l}_silence_thresh_-55\"].iloc[i])\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "            s_delay_df = test_df[test_df[\"Speaker\"] == 'Patient']\n",
    "            # Use a set to store unique indices of valid silences\n",
    "            unique_val_indices = set()\n",
    "            for t_start, t_end in zip(s_delay_df[\"T_start_ms\"], s_delay_df[\"T_end_ms\"]):\n",
    "                for e, (s_start, s_end) in enumerate(test_silences):\n",
    "                    if s_start <= t_end and s_end >= t_start:\n",
    "                        unique_val_indices.add(e)\n",
    "\n",
    "            # Convert unique indices to list of silence intervals\n",
    "            valid_silence = [test_silences[i] for i in sorted(unique_val_indices)]\n",
    "            valid_silences.append(valid_silence)\n",
    "\n",
    "        val_sil_df[f\"min_silence_len_{l}_silence_thresh_-55\"] = valid_silences\n",
    "\n",
    "    return val_sil_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c572b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "SPLIT_TYPE = 'test'\n",
    "\n",
    "r_df, model_data = pd.DataFrame(), pd.DataFrame()\n",
    "t_df0, t_df1 = pd.DataFrame(), pd.DataFrame()\n",
    "\n",
    "all_norm_sums, norm_silence_counts, lng_short_rats = [], [], []\n",
    "all_norm_sums_p, norm_silence_counts_p, lng_short_rats_p = [], [], []\n",
    "corrs, p_values = [], []\n",
    "silence_lengths = [10] + list(range(100, 10_100, 50))\n",
    "\n",
    "for l in silence_lengths:\n",
    "    df0 = labels.reset_index().query(f\"split == {SPLIT_TYPE}\").reset_index(drop=True)\n",
    "    df0[\"silences\"] = pt_silence_df[f\"min_silence_len_{l}_silence_thresh_-55\"]\n",
    "    lst = [df0.silences.iloc[i] for i in range(len(df0))]\n",
    "\n",
    "    sums = []\n",
    "    for i in range(len(df0)):\n",
    "        ss = 0\n",
    "        for j in range(len(lst[i])):\n",
    "            ss += lst[i][j][1] - lst[i][j][0]\n",
    "        sums.append(ss)\n",
    "\n",
    "    avg_silence_durations = []\n",
    "    for i in range(len(lst)):\n",
    "        if len(lst[i]) > 0:\n",
    "            avg_duration = sum([interval[1] - interval[0] for interval in lst[i]]) / len(lst[i])\n",
    "        else:\n",
    "            avg_duration = 0\n",
    "        avg_silence_durations.append(avg_duration)   \n",
    "\n",
    "    norm_sums = [sums[i] / audio_lens[i] for i in range(len(sums))]\n",
    "    r_df[f\"norm_silence_duration_{l}\"] = norm_sums\n",
    "\n",
    "    t = 0.3\n",
    "    lt = 0.5\n",
    "    st = 0.1\n",
    "    lng = [i if i > t else 0 for i in norm_sums]\n",
    "    short = [i if i <= t else 0 for i in norm_sums]\n",
    "    lng_short_rat = [lng[i] / (short[i] or 1) for i in range(len(lng))]\n",
    "    r_df[f\"lng_short_rat_{l}\"] = lng_short_rat\n",
    "    norm_silence_count = [len(lst[i]) / audio_lens[i] for i in range(len(lst))]\n",
    "    r_df[f\"norm_silence_count_{l}\"] = norm_silence_count\n",
    "\n",
    "    df0[\"norm_sums\"] = norm_sums\n",
    "    df0[\"norm_silence_count\"] = norm_silence_count\n",
    "    df0[\"lng_short_rat\"] = lng_short_rat\n",
    "\n",
    "    norm_sums_stat, norm_sums_p_value = stats.mannwhitneyu(\n",
    "        df0[df0['AD_dx'] == 0]['norm_sums'], \n",
    "        df0[df0['AD_dx'] == 1]['norm_sums'], \n",
    "        alternative='two-sided'\n",
    "    )\n",
    "\n",
    "    # Mann-Whitney U test for norm_silence_count\n",
    "    norm_silence_count_stat, norm_silence_count_p_value = stats.mannwhitneyu(\n",
    "        df0[df0['AD_dx'] == 0]['norm_silence_count'], \n",
    "        df0[df0['AD_dx'] == 1]['norm_silence_count'], \n",
    "        alternative='two-sided'\n",
    "    )\n",
    "\n",
    "    # Mann-Whitney U test for lng_short_rat\n",
    "    lng_short_rats_stat, lng_short_rats_p_value = stats.mannwhitneyu(\n",
    "        df0[df0['AD_dx'] == 0]['lng_short_rat'], \n",
    "        df0[df0['AD_dx'] == 1]['lng_short_rat'], \n",
    "        alternative='two-sided'\n",
    "    )\n",
    "\n",
    "    # Independent t-test for norm_sums\n",
    "    # norm_sums_stat, norm_sums_p_value = stats.ttest_ind(\n",
    "    #     df0[df0['AD_dx'] == 0]['norm_sums'], \n",
    "    #     df0[df0['AD_dx'] == 1]['norm_sums'], \n",
    "    #     alternative='two-sided'\n",
    "    # )\n",
    "\n",
    "    # # Independent t-test for norm_silence_count\n",
    "    # norm_silence_count_stat, norm_silence_count_p_value = stats.ttest_ind(\n",
    "    #     df0[df0['AD_dx'] == 0]['norm_silence_count'], \n",
    "    #     df0[df0['AD_dx'] == 1]['norm_silence_count'], \n",
    "    #     alternative='two-sided'\n",
    "    # )\n",
    "\n",
    "    # # Independent t-test for lng_short_rat\n",
    "    # lng_short_rats_stat, lng_short_rats_p_value = stats.ttest_ind(\n",
    "    #     df0[df0['AD_dx'] == 0]['lng_short_rat'], \n",
    "    #     df0[df0['AD_dx'] == 1]['lng_short_rat'], \n",
    "    #     alternative='two-sided'\n",
    "    # )\n",
    "\n",
    "    t_df0[f\"norm_sums_{l}_dx\"] = df0[df0['AD_dx'] == 0]['norm_sums']\n",
    "    t_df1[f\"norm_sums_{l}_dx\"] = df0[df0['AD_dx'] == 1]['norm_sums']\n",
    "    t_df0[f\"norm_silence_count_{l}_dx\"] = df0[df0['AD_dx'] == 0]['norm_silence_count']\n",
    "    t_df1[f\"norm_silence_count_{l}_dx\"] = df0[df0['AD_dx'] == 1]['norm_silence_count']\n",
    "    t_df0[f\"lng_short_rats_{l}_dx\"] = df0[df0['AD_dx'] == 0]['lng_short_rat']\n",
    "    t_df1[f\"lng_short_rats_{l}_dx\"] = df0[df0['AD_dx'] == 1]['lng_short_rat']\n",
    "\n",
    "    model_data[f\"norm_sums_{l}\"] = df0['norm_sums']\n",
    "    model_data[f\"norm_silence_count_{l}\"] = df0['norm_silence_count']\n",
    "    model_data[f\"lng_short_rats_{l}\"] = df0['lng_short_rat']"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
