{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4e137a06-47ce-4b04-8f59-f6134d0360d3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade openai\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "03145b32-6f99-4709-b83e-6b330186bbc8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Selecting cohort of Penn OBSERVER patients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4a0c95fe-607d-4ced-93a6-34c2e7721729",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import tiktoken\n",
    "import time\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "87e979dc-04e3-4961-b3b2-359430d5967c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "directory = \"/Volumes/biomedicalinformatics_analytics/dev_lab_johnson/swimcap/Penn OBSERVER/problem_lists/\"\n",
    "\n",
    "idx, pls = [], []\n",
    "for file in os.listdir(directory):\n",
    "    with open(os.path.join(directory, file), \"r\") as fp:\n",
    "        idx.append(file.rsplit(\".\")[0])\n",
    "        pls.append(fp.read())\n",
    "\n",
    "problem_lists = pd.DataFrame(data=pls, index=idx, columns=[\"problem_list\"])\n",
    "problem_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "af2debc1-a568-4c8a-a66a-d541a3b90039",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def num_tokens_from_messages(messages, model):\n",
    "    \"\"\"Return the number of tokens used by a list of messages.\"\"\"\n",
    "    try:\n",
    "        encoding = tiktoken.encoding_for_model(model)\n",
    "    except KeyError:\n",
    "        print(\"Warning: model not found. Using o200k_base encoding.\")\n",
    "        encoding = tiktoken.get_encoding(\"o200k_base\")\n",
    "    if model in {\n",
    "        \"gpt-3.5-turbo-0125\",\n",
    "        \"gpt-4-0314\",\n",
    "        \"gpt-4-32k-0314\",\n",
    "        \"gpt-4-0613\",\n",
    "        \"gpt-4-32k-0613\",\n",
    "        \"gpt-4o-mini-2024-07-18\",\n",
    "        \"gpt-4o-2024-08-06\"\n",
    "        }:\n",
    "        tokens_per_message = 3\n",
    "        tokens_per_name = 1\n",
    "    elif \"gpt-3.5-turbo\" in model:\n",
    "        print(\"Warning: gpt-3.5-turbo may update over time. Returning num tokens assuming gpt-3.5-turbo-0125.\")\n",
    "        return num_tokens_from_messages(messages, model=\"gpt-3.5-turbo-0125\")\n",
    "    elif \"gpt-4o-mini\" in model:\n",
    "        print(\"Warning: gpt-4o-mini may update over time. Returning num tokens assuming gpt-4o-mini-2024-07-18.\")\n",
    "        return num_tokens_from_messages(messages, model=\"gpt-4o-mini-2024-07-18\")\n",
    "    elif \"gpt-4o\" in model:\n",
    "        print(\"Warning: gpt-4o and gpt-4o-mini may update over time. Returning num tokens assuming gpt-4o-2024-08-06.\")\n",
    "        return num_tokens_from_messages(messages, model=\"gpt-4o-2024-08-06\")\n",
    "    elif \"gpt-4\" in model:\n",
    "        print(\"Warning: gpt-4 may update over time. Returning num tokens assuming gpt-4-0613.\")\n",
    "        return num_tokens_from_messages(messages, model=\"gpt-4-0613\")\n",
    "    else:\n",
    "        raise NotImplementedError(\n",
    "            f\"\"\"num_tokens_from_messages() is not implemented for model {model}.\"\"\"\n",
    "        )\n",
    "    num_tokens = 0\n",
    "    for message in messages:\n",
    "        num_tokens += tokens_per_message\n",
    "        for key, value in message.items():\n",
    "            num_tokens += len(encoding.encode(value))\n",
    "            if key == \"name\":\n",
    "                num_tokens += tokens_per_name\n",
    "    num_tokens += 3  # every reply is primed with <|start|>assistant<|message|>\n",
    "    return num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "348da4f0-ada7-4c4d-a20c-ada8f07cf4b4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# \"content\": f\"Here is a patient's problem list:\\n\\n{row.list}\\n\\nBased on this, label this patient as either \\\"Probable Alzheimer's dementia (AD)\\\" or \\\"Healthy Control\\\". Probable AD should be assigned if the problem list includes relevant diagnostic terms or if there are multiple conditions strongly associated with Alzheimer’s dementia. If the label is \\\"Probable AD\\\", list the specific problems from the problem list that contributed to this decision. If the label is “Healthy Control”, do not include a list of problems. Format your response as follows:\\n\\nLabel: <Probable AD or Healthy Control>\\n{{If \\\"Probable AD\\\", include the following line:}}\\nRelevant problems: <comma-separated list of problems from the problem list relevant to the label>\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cbc4260e-e8f7-43e6-80ea-23dc824bb0a3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "DATABRICKS_TOKEN = dbutils.notebook.entry_point.getDbutils().notebook().getContext().apiToken().get()\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=DATABRICKS_TOKEN,\n",
    "    base_url=\"https://adb-2035410508966251.11.azuredatabricks.net/serving-endpoints\"\n",
    ")\n",
    "\n",
    "model   = \"openai_gpt_4o\"\n",
    "tpm     = 1e6\n",
    "rpm     = 6150\n",
    "\n",
    "prompt  = (\n",
    "    \"Here is a patient's problem list summarizing their active health issues \"\n",
    "    \"(e.g., diagnoses, chronic conditions, injuries):\\n\\n\"\n",
    "    \"{}\\n\\n\"\n",
    "    \"Based on this information, label the patient as either:\\n\\n\"\n",
    "    \"- Probable MCI (Mild Cognitive Impairment), or\\n\"\n",
    "    \"- Healthy Control\\n\\n\"\n",
    "    \"If the problem list includes multiple conditions that are commonly associated \"\n",
    "    \"with cognitive decline, MCI, or Alzheimer's dementia (e.g., memory loss, gait abnormality), consider assigning \"\n",
    "    'the \\\"Probable MCI\\\" label. Otherwise, assign \\\"Healthy Control\\\".\\n\\n'\n",
    "    \"Format your response as follows:\\n\\n\"\n",
    "    \"- Label: <Probable MCI or Healthy Control>\\n\"\n",
    "    \"- Reason: <comma-separated list of relevant issues from the problem list, or \\\"N/A\\\" if Healthy Control>\"\n",
    ")\n",
    "\n",
    "\n",
    "tokens_used = 0\n",
    "t = time.time()\n",
    "for i, row in problem_lists.iterrows():\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt.format(row.problem_list)}]\n",
    "    n_query_tokens = num_tokens_from_messages(messages, model.split(\"_\", maxsplit=1)[1].replace(\"_\", \"-\"))\n",
    "    print(\"N query tokens:\", n_query_tokens)\n",
    "\n",
    "    # elapsed = time.time() - t\n",
    "    # if elapsed < 60:\n",
    "    #     if tokens_used + n_query_tokens > tpm:\n",
    "    #         # print(\"sleeping...\")\n",
    "    #         time.sleep(60 - elapsed)\n",
    "    #         tokens_used += n_query_tokens\n",
    "    # else:\n",
    "    #     tokens_used = 0\n",
    "    #     t = time.time()\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages\n",
    "    )\n",
    "    output = response.choices[0].message.content\n",
    "    n_response_tokens = response.usage.completion_tokens\n",
    "    print(\"N response tokens:\", n_response_tokens)\n",
    "\n",
    "    tokens_used += n_response_tokens\n",
    "\n",
    "    matches = re.findall(r'^\\s*[^:]+:\\s*(.*)', output, re.MULTILINE)\n",
    "    problem_lists.loc[i, \"generated_label\"] = matches[0].rstrip()\n",
    "    problem_lists.loc[i, \"reason\"] = matches[1].rstrip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4b1cef09-1bb0-43d0-bb2c-88c55ce49e35",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "problem_lists.to_excel(\"visit_problem_lists_labeled.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "00_Penn Cohort",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
