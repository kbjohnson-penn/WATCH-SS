{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3282787",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install catboost colorama openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befd4a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from lightgbm import LGBMRegressor, LGBMClassifier, log_evaluation, early_stopping\n",
    "from catboost import CatBoostRegressor, CatBoostClassifier\n",
    "from xgboost import XGBRegressor, XGBClassifier\n",
    "from sklearn.model_selection import cross_val_score, KFold, StratifiedKFold, LeaveOneOut, RepeatedStratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, MinMaxScaler\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
    "from sklearn.svm import SVR, SVC\n",
    "from sklearn.ensemble import AdaBoostRegressor, VotingClassifier, ExtraTreesClassifier, HistGradientBoostingClassifier, GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.neural_network import MLPRegressor, MLPClassifier\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, roc_auc_score, confusion_matrix\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from tqdm import tqdm\n",
    "from colorama import Fore, Back, Style\n",
    "from fasteda import fast_eda\n",
    "import shap\n",
    "\n",
    "from sklearn.metrics import log_loss\n",
    "pd.set_option('display.max_columns', 500)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"threadpoolctl\")\n",
    "\n",
    "from openTSNE import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974826f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "BOLD_TXT =  Style.BRIGHT\n",
    "GREEN_TXT = BOLD_TXT + Fore.GREEN\n",
    "RESET_TXT = Style.RESET_ALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2fc053e",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET = \"AD_dx\"\n",
    "FEATURES = [\n",
    "    \"norm_sums_6100\",\n",
    "    \"norm_sums_6950\",\n",
    "    \"norm_sums_8800\",\n",
    "    \"norm_silence_count_1250\",\n",
    "    \"norm_silence_count_6100\",\n",
    "    \"norm_silence_count_7050\",\n",
    "    \"lng_short_rats_250\",\n",
    "    \"lng_short_rats_400\",\n",
    "    \"lng_short_rats_1050\",\n",
    "    \"age\",\n",
    "    \"gender\",\n",
    "    \"kw_filler_rates\",\n",
    "    \"kw_mean_IFD_imp\",\n",
    "    \"kw_std_IFD_imp\",\n",
    "    \"unia_repetition_rate\",\n",
    "   \"unia_ADJ_rep_rate\",\t\n",
    "    \"unia_ADP_rep_rate\",\t\n",
    "   \"unia_ADV_rep_rate\",\t\n",
    "    \"unia_AUX_rep_rate\",\t\n",
    "    \"unia_CCONJ_rep_rate\",\t\n",
    "  #  \"unia_DET_rep_rate\",\t\n",
    "   \"unia_INTJ_rep_rate\",\t\n",
    "    \"unia_NOUN_rep_rate\",\t\n",
    "   \"unia_NUM_rep_rate\",\t\n",
    "    \"unia_PART_rep_rate\",\t\n",
    "    \"unia_PRON_rep_rate\",\t\n",
    "    \"unia_PROPN_rep_rate\",\t\n",
    "   \"unia_SCONJ_rep_rate\",\t\n",
    "    \"unia_VERB_rep_rate\",\t\n",
    "    \"unia_X_rep_rate\",\n",
    "    \"mlm_sub_error_rate\",\n",
    "    \"mlm_mean_ISED_imp\",\n",
    "    \"mlm_std_ISED_imp\",\n",
    "    \"kw_vague_term_rate\",\t\n",
    "    \"kw_vague_utt_ratio\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63811868",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_data(train_data, test_data):    \n",
    "    scaler = MinMaxScaler() # StandardScaler\n",
    "    scaled_train_data = scaler.fit_transform(train_data[FEATURES])\n",
    "    scaled_test_data = scaler.transform(test_data[FEATURES])\n",
    "    scaled_train_df = pd.concat([pd.DataFrame(scaled_train_data, columns=FEATURES, index=train_data.index), train_data[TARGET]], axis=1)\n",
    "    scaled_test_df = pd.concat([pd.DataFrame(scaled_test_data, columns=FEATURES, index=test_data.index), test_data[TARGET]], axis=1)\n",
    "    return scaled_train_df, scaled_test_df\n",
    "\n",
    "train, test = scale_data(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c2e7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def skf_cv(train_data, model, features, n_splits, n_repeats, kfold_seed, test=test,):\n",
    "    model_name = str(model).split(\"(\")[0]\n",
    "    test_pred_binary_all = np.zeros((len(test), n_splits * n_repeats))\n",
    "    oof_full = np.zeros(len(train_data))\n",
    "    oof_probas = np.zeros(len(train_data))\n",
    "    test_probas = np.zeros(len(test))\n",
    "    f1_scores, prec_scores, rec_scores, acc_scores = [], [], [], []\n",
    "    \n",
    "    print(model_name)\n",
    "    \n",
    "    rskf = RepeatedStratifiedKFold(n_splits=n_splits, n_repeats=n_repeats, random_state=kfold_seed)\n",
    "    \n",
    "    for i, (train_idx, val_idx) in enumerate(tqdm(rskf.split(train_data[features], train_data[TARGET]))):\n",
    "        X_train, X_val = train_data[features].loc[train_idx], train_data[features].loc[val_idx]\n",
    "        y_train, y_val = train_data[TARGET].loc[train_idx], train_data[TARGET].loc[val_idx]\n",
    "\n",
    "        current_model = deepcopy(model)\n",
    "\n",
    "        if model_name in [\"LGBMRegressor\", \"LGBMClassifier\"]:\n",
    "            callbacks = [early_stopping(stopping_rounds=50)]\n",
    "            current_model.fit(X_train, y_train, eval_set=[(X_val, y_val)], callbacks=callbacks)\n",
    "        elif model_name in [\"XGBClassifier\", \"CatBoostClassifier\"]:\n",
    "            current_model.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=10000)\n",
    "        else:\n",
    "            current_model.fit(X_train, y_train)\n",
    "\n",
    "        oof_preds_proba = current_model.predict_proba(X_val)[:, 1] \n",
    "        oof_probas[val_idx] = oof_preds_proba\n",
    "\n",
    "        oof_pred_binary = current_model.predict(X_val)\n",
    "        oof_full[val_idx] = oof_pred_binary\n",
    "\n",
    "        test_pred_binary_all[:, i] = current_model.predict(test[features])\n",
    "        test_preds_proba = current_model.predict_proba(test[features])[:, 1] \n",
    "        test_probas += test_preds_proba / rskf.get_n_splits()\n",
    "\n",
    "        f1_scores.append(f1_score(y_val, oof_pred_binary))\n",
    "        prec_scores.append(precision_score(y_val, oof_pred_binary))\n",
    "        rec_scores.append(recall_score(y_val, oof_pred_binary))\n",
    "        acc_scores.append(accuracy_score(y_val, oof_pred_binary))\n",
    "\n",
    "    test_pred_binary = (np.mean(test_pred_binary_all, axis=1) > 0.5).astype(int)\n",
    "\n",
    "    metrics = {\n",
    "        'model': model_name,\n",
    "        \"cv\": \"RSKF\",\n",
    "        'cv_f1': np.mean(f1_scores),\n",
    "        'test_f1': f1_score(test[TARGET], test_pred_binary, average='binary', zero_division=0),\n",
    "        'cv_precision': np.mean(prec_scores),\n",
    "        'test_precision': precision_score(test[TARGET], test_pred_binary, average='binary', zero_division=0),\n",
    "        'cv_recall': np.mean(rec_scores),\n",
    "        'test_recall': recall_score(test[TARGET], test_pred_binary, average='binary', zero_division=0),\n",
    "        'cv_accuracy': np.mean(acc_scores),\n",
    "        'test_accuracy': accuracy_score(test[TARGET], test_pred_binary)\n",
    "    }\n",
    "    \n",
    "    return metrics, oof_probas, test_probas\n",
    "\n",
    "\n",
    "\n",
    "def loo_cv(train_data, model, features, test=test):\n",
    "    \"\"\"\n",
    "    Train a model using LOO CV and compute F1, precision, recall, and accuracy metrics.\n",
    "    \n",
    "    Parameters:\n",
    "    - train_data: DataFrame containing features and target.\n",
    "    - model: Classifier object (e.g., LGBMClassifier, XGBClassifier, etc.).\n",
    "    - features: List of feature column names.\n",
    "    \"\"\"\n",
    "    model_name = str(model).split(\"(\")[0]\n",
    "    oof_full = np.zeros(len(train_data))\n",
    "    oof_probas = np.zeros(len(train_data))\n",
    "    test_probas = np.zeros(len(test))\n",
    "    test_pred_binary_all = np.zeros((len(test), len(train_data)))\n",
    "\n",
    "    loo = LeaveOneOut()\n",
    "    \n",
    "    for i, (train_idx, val_idx) in enumerate(tqdm(loo.split(train_data[features]), total=len(train_data))):\n",
    "        X_train, X_val = train_data[features].loc[train_idx], train_data[features].loc[val_idx]\n",
    "        y_train, y_val = train_data[TARGET].loc[train_idx], train_data[TARGET].loc[val_idx]\n",
    "        \n",
    "        current_model = deepcopy(model)\n",
    "        \n",
    "        if model_name == \"LGBMClassifier\":\n",
    "            callbacks = [early_stopping(stopping_rounds=50, verbose=False)]\n",
    "            current_model.fit(X_train, y_train, eval_set=[(X_val, y_val)], callbacks=callbacks)\n",
    "        elif model_name in [\"XGBClassifier\", \"CatBoostClassifier\"]:\n",
    "            current_model.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=False)\n",
    "        else:\n",
    "            current_model.fit(X_train, y_train)\n",
    "        \n",
    "        oof_preds_proba = current_model.predict_proba(X_val)[:, 1] \n",
    "        oof_probas[val_idx] = oof_preds_proba\n",
    "\n",
    "        oof_pred_binary = current_model.predict(X_val)\n",
    "        oof_full[val_idx] = oof_pred_binary\n",
    "\n",
    "        test_pred_binary_all[:, i] = current_model.predict(test[features])\n",
    "        test_preds_proba = current_model.predict_proba(test[features])[:, 1] \n",
    "        test_probas += test_preds_proba / len(train_data)\n",
    "    \n",
    "    cm = confusion_matrix(train_data[TARGET], oof_full)\n",
    "    test_pred_binary = (np.mean(test_pred_binary_all, axis=1) > 0.5).astype(int)\n",
    "\n",
    "    metrics = {\n",
    "        'model': model_name,\n",
    "        \"cv\": \"leave-one-out\",\n",
    "        'cv_f1': f1_score(train[TARGET], oof_full, average='binary', zero_division=0),\n",
    "        'test_f1': f1_score(test[TARGET], test_pred_binary, average='binary', zero_division=0),\n",
    "        'cv_precision': precision_score(train[TARGET], oof_full, average='binary', zero_division=0),\n",
    "        'test_precision': precision_score(test[TARGET], test_pred_binary, average='binary', zero_division=0),\n",
    "        'cv_recall': recall_score(train[TARGET], oof_full, average='binary', zero_division=0),\n",
    "        'test_recall': recall_score(test[TARGET], test_pred_binary, average='binary', zero_division=0),\n",
    "        'cv_accuracy': accuracy_score(train[TARGET], oof_full),\n",
    "        'test_accuracy': accuracy_score(test[TARGET], test_pred_binary)\n",
    "    }\n",
    "    \n",
    "    return metrics, cm, oof_probas, test_probas, test_pred_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb5c9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params = {\n",
    "    'objective': 'binary:logistic',\n",
    "    'max_depth': 1, \n",
    "    'n_estimators': 10000,\n",
    "    'early_stopping_rounds': 50,\n",
    "     'colsample_bytree': 0.4,\n",
    "    'random_state': 42,\n",
    "}\n",
    "\n",
    "\n",
    "lgb_params = {\n",
    "  'lambda_l1': 0.001,\n",
    "   'max_depth': 1,\n",
    "    'verbose': -1,\n",
    "    'colsample_bytree': 0.2,\n",
    "    'min_data_in_leaf': 12,\n",
    "    'n_estimators': 10000,\n",
    "    'random_state': 42,\n",
    "    'objective': 'binary',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cee7899",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    LogisticRegression(solver='lbfgs', tol=1e-4, C=0.35),\n",
    "    SVC(C=0.6, probability=True),\n",
    "   HistGradientBoostingClassifier(random_state=1, min_samples_leaf=12, max_depth=3),\n",
    "    LGBMClassifier(**lgb_params),\n",
    "    XGBClassifier(**xgb_params),\n",
    "   RandomForestClassifier(random_state=1, max_depth=3),\n",
    "    KNeighborsClassifier(5)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105cf484",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame()\n",
    "cms = []\n",
    "\n",
    "for e, model in enumerate(models):\n",
    "\n",
    "    loo_metrics, cm, _, _ = loo_cv(\n",
    "        train_data = train,\n",
    "        model = model,\n",
    "        features = FEATURES,\n",
    "    )\n",
    "    cms.append(cm)\n",
    "    result_df = pd.concat([result_df, pd.DataFrame(loo_metrics, index=[e])], axis=0)\n",
    "\n",
    "    skf_metrics, _, _ = skf_cv(\n",
    "        train_data = train,\n",
    "        model = model,\n",
    "        features = FEATURES,\n",
    "        n_splits = 10,\n",
    "        n_repeats = 10,\n",
    "        kfold_seed = 0\n",
    "    )\n",
    "    result_df = pd.concat([result_df, pd.DataFrame(skf_metrics, index=[e])], axis=0)\n",
    "\n",
    "result_df = result_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5372cd00",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.sort_values(\"cv_f1\", ascending=False).round(3).reset_index(drop=True)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
