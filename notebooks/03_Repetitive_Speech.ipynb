{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e19c667c-050c-4f74-8de9-181a6394190d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Detecting Repetitive Speech\n",
    "\n",
    "**TODO**:\n",
    "- Generator + LLM critic experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2917529a-0ba5-42a4-930d-5fd7e78fb584",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport data.adress\n",
    "%aimport detectors.repetitive_speech.unigram_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5e67d695-263e-4656-9b37-449fc567d635",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from pprint import pprint\n",
    "# Evaluation\n",
    "from utils import evaluate\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from scipy.stats import ttest_ind, mannwhitneyu\n",
    "# Generative AI\n",
    "from openai import OpenAI\n",
    "from utils import llm_call\n",
    "import mlflow\n",
    "from mlflow.genai.scorers import Safety, scorer\n",
    "from mlflow.entities import Feedback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "69670ea8-82e9-42cb-a7b9-93388c3a9b1e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b4eedbee-02d2-4b6d-a716-a25ca02887ce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from data.adress import load_transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "53af97ae-a28c-4b02-9bb9-38bc9dd6b896",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "adress_trans = load_transcripts()\n",
    "adress_trans = adress_trans[[\"Speaker\", \"Transcript\", \"Transcript_clean\", \"Repetition\", \"Revision\"]]\n",
    "\n",
    "# Extract annotation based count of repetitions and revisions\n",
    "adress_trans[\"num_repetitions\"] = adress_trans[\"Transcript\"].apply(lambda x: len(re.findall(r\"\\[/\\]\", x)))\n",
    "adress_trans[\"num_revisions\"] = adress_trans[\"Transcript\"].apply(lambda x: len(re.findall(r\"\\[//\\]\", x)))\n",
    "\n",
    "adress_trans.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "400169cf-c16e-45a7-9092-6a93445ac96b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "trn_pt_utt_idx = (adress_trans.index.get_level_values(\"split\") == \"train\") & (adress_trans[\"Speaker\"] == \"Patient\")\n",
    "dev_pt_utt_idx = (adress_trans.index.get_level_values(\"split\") == \"dev\")   & (adress_trans[\"Speaker\"] == \"Patient\")\n",
    "tst_pt_utt_idx = (adress_trans.index.get_level_values(\"split\") == \"test\")  & (adress_trans[\"Speaker\"] == \"Patient\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "00fde8d2-c6b9-4fa4-acd5-2e4150f287b5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Baseline: Unigram Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b83cd553-d204-4233-9213-a71218286810",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from detectors.repetitive_speech.unigram_analysis import UnigramAnalysisDetector\n",
    "from utils import create_custom_nlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d9e132d5-76aa-460e-96d9-f746965e7d9d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Explore detector configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "86c97617-cff3-4823-a670-c808766455d8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "21c0aa80-012c-433e-933d-60b1a10f24ae",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "window_sizes = [1, 2, 3, 5, 10]\n",
    "comparators = [\"exact\", \"lemma_exact\"]\n",
    "\n",
    "configs = {f\"max_w_{cfg[0]}_comp_{cfg[1]}\": cfg for cfg in product(window_sizes, comparators)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "238c403a-373f-4e51-a432-d235b50b8ce2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def run(cfg_name, cfg, dataset):\n",
    "    # Create spaCy vocab\n",
    "    nlp = create_custom_nlp()\n",
    "    # Initialize n-gram analysis detector with config\n",
    "    d = UnigramAnalysisDetector(nlp, *cfg)\n",
    "    # Run detector on dataset\n",
    "    outputs = dataset[\"Transcript_clean\"].apply(d.detect)\n",
    "    # Evaluate performance\n",
    "    true = dataset[\"Repetition\"]\n",
    "    pred = outputs.apply(lambda x: len(x[\"detections\"]) > 0).astype(int)\n",
    "    scores = evaluate(true, pred)\n",
    "    return cfg_name, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "49e92403-5572-46b2-b329-c07bfde92a02",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "results = Parallel(n_jobs=10, return_as=\"generator_unordered\")(delayed(run)(cfg_name, configs[cfg_name], adress_trans.loc[trn_pt_utt_idx]) for cfg_name in configs)\n",
    "results = [res for res in tqdm(results, total=len(configs))]\n",
    "\n",
    "configs, cfg_scores = zip(*results)\n",
    "table = pd.DataFrame(cfg_scores, index=configs)\n",
    "# table.to_csv(\"train_results/repetition_trn_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8fdcec91-320a-4ba3-94c9-1a385b98a43a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "table.sort_values(\"f1\", ascending=False).round(3)\n",
    "# print(table.round(3).to_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "75a329fb-ad74-4325-a0a6-fc13db665b1f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Evaluate the best configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6a2b131c-1bd2-4956-a8c0-65c55c0eb9f6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# create custom spaCy\n",
    "nlp = create_custom_nlp()\n",
    "# initialize detector\n",
    "repetition_detector_final = UnigramAnalysisDetector(nlp, 2, \"exact\")\n",
    "# run on all data\n",
    "adress_trans[\"unia_dets\"] = adress_trans.apply(lambda x: repetition_detector_final.detect(x[\"Transcript_clean\"]) if x[\"Speaker\"] == \"Patient\" else pd.NA, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "137dccac-0fba-4601-801c-7179d78c946d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###### Performance on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0bb559ed-99c6-4ead-b866-75a30fd5adc1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "true = adress_trans.loc[tst_pt_utt_idx, \"Repetition\"]\n",
    "pred = adress_trans.loc[tst_pt_utt_idx, \"unia_dets\"].apply(lambda x: len(x[\"detections\"]) > 0).astype(int)\n",
    "print(evaluate(true, pred, return_latex=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "04688e6a-c7cb-4760-9141-311b39d47fa7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## LLM-Based Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "11fe6c02-dbee-4ddf-85a7-3e678224c1a6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "mlflow_creds = mlflow.utils.databricks_utils.get_databricks_host_creds()\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=mlflow_creds.token,\n",
    "    base_url=f\"{mlflow_creds.host}/serving-endpoints\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0ca504f7-4817-4263-a185-c3fe8f694a13",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "datasets = {\n",
    "    \"train\": [],\n",
    "    \"dev\": [],\n",
    "    \"test\": []\n",
    "}\n",
    "\n",
    "for (split, pt_id, utt_num), row in adress_trans.loc[adress_trans[\"Speaker\"] == \"Patient\"].iterrows():\n",
    "    datasets[split].append({\n",
    "        \"split\": split,\n",
    "        \"ID\": pt_id,\n",
    "        \"utt_num\": utt_num,\n",
    "        \"inputs\": {\"text\": row[\"Transcript_clean\"]},\n",
    "        \"expectations\": {\"has_repetition\": bool(row[\"Repetition\"])}\n",
    "    })\n",
    "\n",
    "# pprint(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "63695445-324f-4ee6-a666-71283a8793be",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "@scorer\n",
    "def correct(expectations, outputs):\n",
    "    return Feedback(value=(expectations[\"has_repetition\"] == (len(outputs[\"detections\"]) > 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d42cf6b5-d82c-4185-965c-62c8f3ddc767",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def process_mlflow_outputs(result):\n",
    "    outputs = result.tables[\"eval_results\"][[\"response\", \"assessments\"]]\n",
    "    outputs[\"pred\"] = outputs[\"response\"].apply(lambda x: (len(x[\"detections\"]) > 0) if type(x) == dict else False).astype(int)\n",
    "    outputs[\"label\"] = outputs[\"assessments\"].apply(lambda x: [a[\"value\"] for a in x if a[\"name\"] == \"has_repetition\"][0]).astype(int)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "23c4066a-04e4-4bd1-8c38-eb46d788d1f5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Explore different prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9931f132-0150-4659-896f-07747e6bb4e8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Your task is to analyze an utterance and identify all instances of exact repetition and significant semantic revision.\n",
    "\n",
    "**INSTRUCTIONS**\n",
    "1. Identify all repetitions and revisions. A \"repetition\" is a retracing without correction where the speaker repeats their words without changes. A \"revision\" is a retracing with correction and occurs when the speaker changes something (usually the syntax) of an utterance but maintains the same idea.\n",
    "2. You must output a list of pairs. For each repetition or revision, the pair contains (1) tuple of the start and end character index of the first part of the repeated or revised text and (2) tuple of the start and end character index of the second part of the repeated or revised text. If no repetitions or revisions are found, the list must be empty.\n",
    "\n",
    "**Input:**\n",
    "{}\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"Your task is to analyze the following utterances and identify instances of repetition.\n",
    "\n",
    "**INSTRUCTIONS:**\n",
    "1. **Input Format**: The input will be a JSON object with a single key \"utterances\". The value will be a list of objects, where each object has the \"text\" to be analyzed.\n",
    "2. **Task**: For each utterance object in the input, identify all instances of repetition its text. A \"repetition\" is when a sound, word or phrase is repeated exactly. Some repetition text between repeated content is allowed.\n",
    "3. **Output Format**: Your output must be a JSON object with a single key \"utterances\". The value will be a list of objects, one for each utterance from the input. Each object in the \"utterances\" list must contain:\n",
    "- The original \"text\".\n",
    "- A \"repetitions\" list. This list should contain one sub-list for each detected repetition. Each sub-list must contain a pair of spans: one for the original instance and one for the repeated instance. Each span should be a list of two integers: the start and end character index. \n",
    "\n",
    "**INPUT JSON:**\n",
    "{}\n",
    "\"\"\"\n",
    "\"Identify all instances where the patient repeats the same sounds, words, or phrases--either consecutively or non-consecutively--in a way that indicates cognitive impairment in the following utterance:\\n\\n{}\\n\\nReturn a bullet point list, where each bullet contains a complete quote of the full phrase in which the repetition occurs, exactly as spoken by the patient. Start the quote at the first repeated sound, word, or phrase and end the quote after the last repeated sound, word, or phrase. Do not include any explanations. Do not include repetition prompted by the provider. If no repetitions are found, return \\\"None\\\".\"\n",
    "\n",
    "# v0\n",
    "\"\"\"# INSTRUCTIONS\n",
    "You are a neurologist analyzing a patient\"s speech sample for signs of cognitive impairment. Your task is to identify all instances where the patient repeats the same sounds, words, or phrases--either consecutively or non-consecutively--in the provided utterance below.\n",
    "\n",
    "Your output must be a single JSON object with a single key \"detections\" whose value is an array of JSON objects. Each object in the array represents one detected repetition and must have the following three keys-value pairs:\n",
    "- \"type\": \"repetition\".\n",
    "- \"text\": The verbatim text of the repeated word or phrase.\n",
    "- \"span1\": The character span for the first occurrence of the repeated text.\n",
    "- \"span2\": The character span for the second occurrence of the repeated text.\n",
    "\n",
    "# UTTERANCE\n",
    "{}\n",
    "\"\"\"\n",
    "\n",
    "# v1\n",
    "\"\"\"# INSTRUCTIONS\n",
    "You are a neurologist analyzing a patient\"s speech sample for signs of cognitive impairment. Your task is to identify all clinically significant instances of repetition in the provided utterance below. Include repetition due to hesitation, stuttering, word finding difficulty, and speech planning.\n",
    "\n",
    "Your output must be a single JSON object with a single key \"detections\" whose value is an array of JSON objects. Each object in the array represents one detected repetition and must have the following three keys-value pairs:\n",
    "- \"type\": \"repetition\".\n",
    "- \"text\": The verbatim text of the repeated word or phrase.\n",
    "- \"span1\": The character span for the first occurrence of the repeated text.\n",
    "- \"span2\": The character span for the second occurrence of the repeated text.\n",
    "\n",
    "# UTTERANCE\n",
    "{}\n",
    "\"\"\"\n",
    "\n",
    "# v2\n",
    "\"\"\"# INSTRUCTIONS\n",
    "You are a neurologist analyzing a patient\"s speech sample for signs of cognitive impairment. Your task is to identify all clinically significant instances of repetition in the provided utterance below. Focus only on repetitions that appear involuntary and disrupt the natural flow of speech.\n",
    "\n",
    "Your output must be a single JSON object with a single key \"detections\" whose value is an array of JSON objects. Each object in the array represents one detected repetition and must have the following three keys-value pairs:\n",
    "- \"type\": \"repetition\".\n",
    "- \"text\": The verbatim text of the repeated word or phrase.\n",
    "- \"span1\": The character span for the first occurrence of the repeated text.\n",
    "- \"span2\": The character span for the second occurrence of the repeated text.\n",
    "\n",
    "# UTTERANCE\n",
    "{}\n",
    "\"\"\"\n",
    "\n",
    "# v3\n",
    "\"\"\"# INSTRUCTIONS\n",
    "You are a neurologist analyzing a patient\"s speech sample for signs of cognitive impairment. Your task is to identify all clinically significant instances of repetition in the provided utterance below. Focus only on repetitions that appear involuntary and disrupt the natural flow of speech. Do not flag words that repeat for valid grammatical reasons\n",
    "\n",
    "Your output must be a single JSON object with a single key \"detections\" whose value is an array of JSON objects. Each object in the array represents one detected repetition and must have the following three keys-value pairs:\n",
    "- \"type\": \"repetition\".\n",
    "- \"text\": The verbatim text of the repeated word or phrase.\n",
    "- \"span1\": The character span for the first occurrence of the repeated text.\n",
    "- \"span2\": The character span for the second occurrence of the repeated text.\n",
    "\n",
    "# UTTERANCE\n",
    "{}\n",
    "\"\"\"\n",
    "\n",
    "# v4\n",
    "\"\"\"# INSTRUCTIONS\n",
    "You are a neurologist analyzing a patient\"s speech sample for signs of cognitive impairment. Your task is to identify all clinically significant instances of immediate, verbatim repetition in the provided utterance below. Focus only on repetitions that appear involuntary and disrupt the natural flow of speech. Do not flag words that repeat for valid grammatical reasons.\n",
    "\n",
    "Your output must be a single JSON object with a single key \"detections\" whose value is an array of JSON objects. Each object in the array represents one detected repetition and must have the following three keys-value pairs:\n",
    "- \"type\": \"repetition\".\n",
    "- \"text\": The verbatim text of the repeated word or phrase.\n",
    "- \"span1\": The character span for the first occurrence of the repeated text.\n",
    "- \"span2\": The character span for the second occurrence of the repeated text.\n",
    "\n",
    "# UTTERANCE\n",
    "{}\n",
    "\"\"\"\n",
    "\n",
    "# v5\n",
    "\"\"\"# INSTRUCTIONS\n",
    "You are a neurologist analyzing a patient\"s speech sample for signs of cognitive impairment. Your task is to identify all clinically significant instances of immediate, verbatim repetition of whole words or phrases in the provided utterance below. Focus only on repetitions that appear involuntary and disrupt the natural flow of speech. Do not flag words that repeat for valid grammatical reasons.\n",
    "\n",
    "Your output must be a single JSON object with a single key \"detections\" whose value is an array of JSON objects. Each object in the array represents one detected repetition and must have the following three keys-value pairs:\n",
    "- \"type\": \"repetition\".\n",
    "- \"text\": The verbatim text of the repeated word or phrase.\n",
    "- \"span1\": The character span for the first occurrence of the repeated text.\n",
    "- \"span2\": The character span for the second occurrence of the repeated text.\n",
    "\n",
    "# UTTERANCE\n",
    "{}\n",
    "\"\"\"\n",
    "\n",
    "# v6\n",
    "\"\"\"# INSTRUCTIONS\n",
    "You are a neurologist analyzing a patient\"s speech sample for signs of cognitive impairment. Your task is to identify all clinically significant instances of immediate, verbatim repetition of whole words or phrases in the provided utterance below. Focus only on repetitions that appear involuntary and disrupt the natural flow of speech. Do not flag words that repeat for valid grammatical reasons. Every detected repetition MUST correspond to an exact substring found within the provided utterance.\n",
    "\n",
    "Your output must be a single JSON object with a single key \"detections\" whose value is an array of JSON objects. Each object in the array represents one detected repetition and must have the following three keys-value pairs:\n",
    "- \"type\": \"repetition\".\n",
    "- \"text\": The verbatim text from the first occurrence of the repeated word or phrase.\n",
    "- \"s1\": The starting character index for the first occurrence of \"text\".\n",
    "- \"s2\": The starting character index for the second occurrence of \"text\".\n",
    "\n",
    "# UTTERANCE\n",
    "{}\n",
    "\"\"\"\n",
    "\n",
    "# v7\n",
    "\"\"\"# INSTRUCTIONS\n",
    "You are a neurologist analyzing a patient\"s speech sample for signs of cognitive impairment. Your task is to identify all clinically significant instances of immediate, verbatim repetition in the provided utterance below. Focus only on repetitions that appear involuntary and disrupt the natural flow of speech. Do not flag words that repeat for valid grammatical reasons.\n",
    "\n",
    "Your output must be a single JSON object with a single key \"detections\" whose value is an array of JSON objects. Each object in the array represents one detected repetition and must have the following four keys-value pairs:\n",
    "- \"type\": \"repetition\".\n",
    "- \"text\": The verbatim text of the repeated word or phrase.\n",
    "- \"start1\": The character index where the FIRST occurrence of the repeated text begins.\n",
    "- \"start2\": The character index where the SECOND occurrence of the repeated text begins.\n",
    "\n",
    "# UTTERANCE\n",
    "{}\n",
    "\"\"\"\n",
    "\n",
    "version = \"4_3\"\n",
    "prompt = \"\"\"# INSTRUCTIONS\n",
    "You are a neurologist analyzing a patient\"s speech sample for signs of cognitive impairment. \n",
    "\n",
    "Your task is to identify all clinically significant instances of word repetition in the provided input utterance below. \n",
    "\n",
    "### Definition\n",
    "Word repetition is an involuntary, immediate verbatim repeat of a whole word, which disrupts the flow of speech and signals a potential struggle with speech production. Do not flag words that repeat for valid grammatical reasons (e.g., \"I knew that that was the problem.\") or for emphasis (e.g., \"very very\"). Do not flag word repetitions that are part of a self-correction or phrasal restart (e.g., in \"He went to the store [silence] to the bank\", the repetition of \"to\" and \"the\" should be ignored). Do not flag filler sounds as repetitions. Do not flag partial-word stutters (e.g., \"s sound\") or different forms of the same word (e.g., \"get getting\").\n",
    "\n",
    "### Output Format\n",
    "Your output must be a single JSON object with a single key \"detections\" whose value is an array of JSON objects. Each object in the array represents one detected word repetition and must have the following keys-value pairs:\n",
    "- \"type\": \"repetition\".\n",
    "- \"text\": The verbatim text of the detected repeat word.\n",
    "- \"span\": The character span of the first occurence of \"text\" in the provided input.\n",
    "- \"span2\": The character span of the second occurrence of \"text\" in the provided input.\n",
    "\n",
    "# INPUT\n",
    "{input_text}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a7de5263-9e4a-4a7c-a2eb-76c8a84376e4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "fn = lambda text: llm_call(client, \"openai_gpt_4o\", None, prompt.format(input_text=text), {\"type\": \"json_object\"})\n",
    "\n",
    "with mlflow.start_run(run_name=f\"gpt_trn_pV{version}\"): \n",
    "    gpt_dets_trn = mlflow.genai.evaluate(\n",
    "        data=datasets[\"train\"],\n",
    "        predict_fn=fn,\n",
    "        scorers=[correct]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "66e70ec5-e737-4e21-a15d-f8c371886ded",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "outputs = process_mlflow_outputs(gpt_dets_trn)\n",
    "outputs.to_pickle(f\"llm_outputs/repetition_trn_gpt_pV{version}.pkl\")\n",
    "\n",
    "print(evaluate(outputs[\"label\"], outputs[\"pred\"], return_latex=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8084b5be-5db2-48ac-981e-cdf361f75b31",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "0.513 & 0.953 & 0.667 & 0.918 & 0.934 \\\\\n",
    "\n",
    "0.472 & 0.976 & 0.636 & 0.904 & 0.937 \\\\"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "94a624fa-8499-46e3-aeec-7d834dbd0d83",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##### Try few-shot prompting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a28bf33b-716c-488c-93a3-6f83fcdabb9b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "First look at errors on the dev dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f21e132a-f12e-4dee-b7c9-e101686eb52f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "fn = lambda text: llm_call(client, \"openai_gpt_4o\", None, prompt.format(input_text=text), {\"type\": \"json_object\"})\n",
    "\n",
    "with mlflow.start_run(run_name=f\"gpt_dev_pV{version}\"): \n",
    "    gpt_dets_trn = mlflow.genai.evaluate(\n",
    "        data=datasets[\"dev\"],\n",
    "        predict_fn=fn,\n",
    "        scorers=[correct]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a7b203af-90e8-4ca1-bf84-9b0e4e94471c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Then evaluate again on train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "04ccc585-f4fb-463c-a2ff-f911afa06271",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "version = \"4_3_fewshot\"\n",
    "fs_prompt = \"\"\"# INSTRUCTIONS\n",
    "You are a neurologist analyzing a patient\"s speech sample for signs of cognitive impairment. \n",
    "\n",
    "Your task is to identify all clinically significant instances of word repetition in the provided input utterance below. \n",
    "\n",
    "### Definition\n",
    "Word repetition is an involuntary, immediate verbatim repeat of a whole word, which disrupts the flow of speech and signals a potential struggle with speech production. Do not flag words that repeat for valid grammatical reasons (e.g., \"I knew that that was the problem.\") or for emphasis (e.g., \"very very\"). Do not flag word repetitions that are part of a self-correction or phrasal restart (e.g., in \"He went to the store [silence] to the bank\", the repetition of \"to\" and \"the\" should be ignored). Do not flag filler sounds as repetitions. Do not flag partial-word stutters (e.g., \"s sound\") or different forms of the same word (e.g., \"get getting\").\n",
    "\n",
    "### Output Format\n",
    "Your output must be a single JSON object with a single key \"detections\" whose value is an array of JSON objects. Each object in the array represents one detected word repetition and must have the following keys-value pairs:\n",
    "- \"type\": \"repetition\".\n",
    "- \"text\": The verbatim text of the detected repeat word.\n",
    "- \"span\": The character span of the first occurence of \"text\" in the provided input.\n",
    "- \"span2\": The character span of the second occurrence of \"text\" in the provided input.\n",
    "\n",
    "# EXAMPLES\n",
    "**Input**: two s uh two cups and a plate are on the um counter there .\n",
    "**Correct Output**: \n",
    "{{\n",
    "    \"detections\": [\n",
    "        {{\"type\": \"repetition\", \"text\": \"two\", \"span\": [0, 3], \"span2\": [9, 12]}},\n",
    "    ]\n",
    "}}\n",
    "\n",
    "**Input**: and he has a cookie in each hand, handing about to hand one cookie to the little girl who is standing there with her hand reached up for the cookie .\n",
    "**Incorrect Output**: \n",
    "{{\n",
    "    \"detections\": [\n",
    "        {{\"type\": \"repetition\", \"text\": \"hand\", \"span\": [28, 32], \"span2\": [52, 56]}},\n",
    "        {{\"type\": \"repetition\", \"text\": \"cookie\", \"span\": [14, 20], \"span2\": [61, 67]}}\n",
    "    ]\n",
    "}}\n",
    "**Error**: These are not immediate repetitions but rather normal word reuse in different contexts.\n",
    "\n",
    "**Input**: and her brother's taking cookies out of the cookie jar .\n",
    "**Incorrect Output**: \n",
    "{{\n",
    "    \"detections\": [\n",
    "        {{\"type\": \"repetition\", \"text\": \"cookie\", \"span\": [37, 43], \"span2\": [51, 57]}},\n",
    "    ]\n",
    "}}\n",
    "**Error**: \"cookies\" and \"cookie\" are different word forms and should not be flagged as repetitions.\n",
    "\n",
    "# INPUT\n",
    "{input_text}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dd9a2f04-c161-4006-aec0-9d2ef2af7383",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "fn = lambda text: llm_call(client, \"openai_gpt_4o\", None, fs_prompt.format(input_text=text), {\"type\": \"json_object\"})\n",
    "\n",
    "with mlflow.start_run(run_name=f\"gpt_trn_pV{version}\"): \n",
    "    gpt_fs_dets_trn = mlflow.genai.evaluate(\n",
    "        data=datasets[\"train\"],\n",
    "        predict_fn=fn,\n",
    "        scorers=[correct]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5d97e2f1-4850-4801-b70b-055d98c222b4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "outputs = process_mlflow_outputs(gpt_dets_trn)\n",
    "outputs.to_pickle(f\"llm_outputs/repetition_trn_gpt_pV{version}.pkl\")\n",
    "\n",
    "print(evaluate(outputs[\"label\"], outputs[\"pred\"], return_latex=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e7fd5bb5-2e2d-458a-b3e3-5bbdf66e5bb4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "0.534 & 0.929 & 0.678 & 0.924 & 0.927 \\\\"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bacaeda0-f938-4a29-b311-0d703f3b1ae0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##### Evaluate the best configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6cbe6769-dc3d-493d-b67d-2f624e3b96ab",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "fn = lambda text: llm_call(client, \"openai_gpt_4o\", None, prompt.format(input_text=text), {\"type\": \"json_object\"})\n",
    "\n",
    "with mlflow.start_run(run_name=f\"gpt_tst_pV{version}\") as run:\n",
    "    gpt_dets_tst = mlflow.genai.evaluate(\n",
    "        predict_fn=fn,\n",
    "        data=datasets[\"test\"],\n",
    "        scorers=[correct]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c76a0b70-83ba-40fd-b05e-166170ac2ea6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "outputs = process_mlflow_outputs(gpt_dets_tst)\n",
    "outputs.to_pickle(f\"llm_outputs/repetition_tst_gpt_pV{version}.pkl\")\n",
    "\n",
    "print(evaluate(outputs[\"label\"], outputs[\"pred\"], return_latex=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c88e795f-2ea3-4330-bce5-978b1ab6892c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Generator + LLM Critic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "badcc467-610f-4ff5-9845-ed8f080e95bd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###### Investigate the failure cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "79a5ea89-58c3-4fcc-835a-aa6a2f88f742",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "with pd.option_context(\"display.max_rows\", None, \"display.max_colwidth\", None):\n",
    "    print(\"False positives:\")\n",
    "    pprint(adress_trans.loc[dev_pt_utt_idx & (adress_trans[\"Repetition\"] == 0) & (adress_trans[\"na_dets\"].apply(lambda x: len(x[\"detections\"]) > 0 if type(x) == dict else False)), [\"Transcript\", \"na_dets\"]].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8d67db4e-51d8-47a4-83dd-46c26ee7f0e7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "with pd.option_context(\"display.max_rows\", None, \"display.max_colwidth\", None):\n",
    "    print(\"False negatives:\")\n",
    "    pprint(adress_trans.loc[dev_pt_utt_idx & (adress_trans[\"Repetition\"] == 1) & (adress_trans[\"na_dets\"].apply(lambda x: len(x[\"detections\"]) == 0 if type(x) == dict else False)), [\"Transcript\"]].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bbe68c41-3ec9-44f8-8c1c-30fc664b87e5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Summary metrics for repetition detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aedf4ce7-2e37-4bd3-ba85-4bb96d327656",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from data.adress import load_outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "777da014-9e77-4362-9c54-7a589abde80e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "outcomes = load_outcomes()\n",
    "outcomes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6e707ba8-0fac-4940-83cd-4693739dded7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "trn_pts = outcomes.loc[(outcomes.index.get_level_values(\"split\") == \"train\")].index.values\n",
    "trn_ad_pts = outcomes.loc[(outcomes.index.get_level_values(\"split\") == \"train\") & (outcomes[\"AD_dx\"] == 1)].index.values\n",
    "trn_cn_pts = outcomes.loc[(outcomes.index.get_level_values(\"split\") == \"train\") & (outcomes[\"AD_dx\"] == 0)].index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9736006b-ffe5-4846-b3c3-f8d97d80fa55",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "tst_pts = outcomes.loc[(outcomes.index.get_level_values(\"split\") == \"test\")].index.values\n",
    "tst_ad_pts = outcomes.loc[(outcomes.index.get_level_values(\"split\") == \"test\") & (outcomes[\"AD_dx\"] == 1)].index.values\n",
    "tst_cn_pts = outcomes.loc[(outcomes.index.get_level_values(\"split\") == \"test\") & (outcomes[\"AD_dx\"] == 0)].index.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8d1fd398-d98b-40e2-8b9a-508ce3137f88",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Repetition Rate**: number of repetitions / total number of spoken words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dfb1d626-9abd-4c47-aef9-3e3b244c299a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def compute_repetition_rate(outputs):\n",
    "    num = outputs.apply(lambda x: len(x[\"detections\"]) if not pd.isna(x) else 0).groupby(level=(\"split\", \"ID\")).sum()\n",
    "    den = adress_trans.apply(lambda x: sum([1 for token in nlp(x[\"Transcript_clean\"]) if not (token.is_punct or token.is_space or token._.is_silence_tag or token._.is_inaudible_tag or token._.is_event_tag)]) if x[\"Speaker\"] == \"Patient\" else 0, axis=1).groupby(level=(\"split\", \"ID\")).sum()\n",
    "    return 100 * num / den"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5967d031-d7cd-4ac8-be06-4d2d93971bfd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# outcomes[\"gt_repetition_rate\"] = compute_repetition_rate(adress_trans[\"num_repetitions\"].apply(lambda x: {\"detections\": [0] * x}))\n",
    "outcomes[\"gt_revision_rate\"] = compute_repetition_rate(adress_trans[\"num_revisions\"].apply(lambda x: {\"detections\": [0] * x}))\n",
    "outcomes[\"unia_repetition_rate\"] = compute_repetition_rate(adress_trans[\"unia_dets\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "31f275d2-b8e3-47ff-8de5-f560f1e77bdb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Part-of-Speech Repetition Counts**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dad812ff-d765-44ad-bab7-871f9465ff02",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "POS = [\n",
    "    \"ADJ\",      # adjective\n",
    "    \"ADP\",      # adposition\n",
    "    \"ADV\",      # adverb\n",
    "    \"AUX\",      # auxiliary\n",
    "    \"CCONJ\",    # coordinating conjunction\n",
    "    \"DET\",      # determiner\n",
    "    \"INTJ\",     # interjection\n",
    "    \"NOUN\",     # noun\n",
    "    \"NUM\",      # numeral\n",
    "    \"PART\",     # particle\n",
    "    \"PRON\",     # pronoun\n",
    "    \"PROPN\",    # proper noun\n",
    "    # \"PUNCT\",    # punctuation\n",
    "    \"SCONJ\",    # subordinating conjunction\n",
    "    # \"SYM\",      # symbol\n",
    "    \"VERB\",     # verb\n",
    "    \"X\",        # other\n",
    "    # \"SPACE\",    # space\n",
    "]\n",
    "\n",
    "def pos_repetition_counts(output_name):\n",
    "    pos_metrics = pd.DataFrame(index=outcomes.index, columns=POS, dtype=float)\n",
    "\n",
    "    for (split, pt_id) in pos_metrics.index:\n",
    "        counts = dict.fromkeys(POS, 0)\n",
    "        num_words = 0\n",
    "        for utt_num, row in adress_trans.loc[(split, pt_id)].iterrows():\n",
    "            if row[\"Speaker\"] == \"Patient\":\n",
    "                num_words += sum([1 for token in nlp(row[\"Transcript_clean\"]) if not (token.is_punct or token.is_space or token._.is_silence_tag or token._.is_inaudible_tag or token._.is_event_tag)])\n",
    "\n",
    "                if row[output_name][\"detections\"]:\n",
    "                    for det in row[output_name][\"detections\"]:\n",
    "                        doc = nlp(det[\"text1\"])\n",
    "                        try:\n",
    "                            counts[doc[0].pos_] += 1                              \n",
    "                        except KeyError as e:\n",
    "                            print(e)\n",
    "                            print(row[\"Transcript_clean\"])\n",
    "                            print(det)\n",
    "\n",
    "        for pos in POS:\n",
    "            pos_metrics.loc[(split, pt_id), pos] = 100 * counts[pos] / num_words\n",
    "\n",
    "    return pos_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2d558de5-3f01-4bc1-ad7a-41294e11f349",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "outcomes[[\"unia_\" + pos + \"_rep_rate\" for pos in POS]] = pos_repetition_counts(\"unia_dets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0b0b02fe-a480-4199-9e76-27b6dea01837",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Analyze correlation between our metrics and the outcome variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ead37644-e6b1-434c-b4d9-b1667f515b7a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Generates the rows of Table 10 and 11\n",
    "def analysis(split_idx, split_ad, split_cn, metrics):\n",
    "    for m in metrics:\n",
    "        ## score averages\n",
    "        mean_ad = outcomes.loc[split_ad, m].mean()\n",
    "        std_ad = outcomes.loc[split_ad, m].std()\n",
    "        mean_cn = outcomes.loc[split_cn, m].mean()\n",
    "        std_cn = outcomes.loc[split_cn, m].std()\n",
    "\n",
    "        ## correlation metrics\n",
    "        res_ttest = ttest_ind(outcomes.loc[split_idx, \"AD_dx\"], outcomes.loc[split_idx, m])\n",
    "        res_mannw = mannwhitneyu(outcomes.loc[split_idx, \"AD_dx\"], outcomes.loc[split_idx, m])\n",
    "        res_auc   = roc_auc_score(outcomes.loc[split_idx, \"AD_dx\"], outcomes.loc[split_idx, m])\n",
    "\n",
    "        print(\"%s & %.2f (%.2f) & %.2f (%.2f) & %.2f (%s) & %.2f (%s) & %.2f \\\\\\\\\" % \n",
    "                (m,\n",
    "                mean_ad,\n",
    "                std_ad,\n",
    "                mean_cn,\n",
    "                std_cn,\n",
    "                res_ttest.statistic,\n",
    "                str(round(res_ttest.pvalue, 3)) if res_ttest.pvalue >= 0.001 else \"$<$0.001\", \n",
    "                res_mannw.statistic, \n",
    "                str(round(res_ttest.pvalue, 3)) if res_ttest.pvalue >= 0.001 else \"$<$0.001\",\n",
    "                res_auc)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "248e29da-f33a-4397-9d7f-dedbda8f25cd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "mets = [\n",
    "    # \"gt_repetition_rate\", \n",
    "    # \"gt_revision_rate\", \n",
    "    \"unia_repetition_rate\"\n",
    "] + [\"unia_\" + pos + \"_rep_rate\" for pos in POS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b2cdce95-a5c1-4a6b-86d3-8f1355936b7c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "analysis(trn_pts, trn_ad_pts, trn_cn_pts, mets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8d16685c-3ee3-4826-a2a3-62247744edf9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "outcomes[[\"unia_repetition_rate\"] + [\"unia_\" + pos + \"_rep_rate\" for pos in POS]].to_csv(\"repetition_feats.csv\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "03_Repetitive_Speech",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
